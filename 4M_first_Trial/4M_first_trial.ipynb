{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import optuna for HPO\n",
    "import optuna\n",
    "# Import PPO for algos\n",
    "from stable_baselines3 import PPO\n",
    "# Evaluate Policy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "# Import wrappers\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "import os\n",
    "LOG_DIR = './logs/'\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)\n",
    "\n",
    "OPT_DIR = './opt_modeldata/'\n",
    "if not os.path.exists(OPT_DIR):\n",
    "    os.makedirs(OPT_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Optional, Tuple\n",
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Box, MultiBinary, Discrete\n",
    "import numpy as np\n",
    "import os\n",
    "from stable_baselines3 import PPO , SAC\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import FrameStack\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Initialize SummaryWriter\n",
    "\n",
    "\n",
    "# i) can buy (to sell in upper price(buy)) and hold for a time period and then close,\n",
    "# ii) can buy (to sell in lower price(sell)) and hold for a time period and then close,\n",
    "# iii) observe the market and do nothing\n",
    "# 1) buy_open 2) sell_open 3) Close 4) hold 5) Do nothing\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data\n",
    "        #WILL CHANGE max step later\n",
    "        self.MAXIMUM_AMOUNT_OF_TIME_FOR_HOLDING = 100\n",
    "        \n",
    "        log_dir = \"./logs\"  # Change this to the desired log directory\n",
    "        self.writer = SummaryWriter(log_dir)\n",
    "\n",
    "        self.OWN_CURRENCY_AMOUNT = np.random.randint(10, 100)\n",
    "        self.USED_CURRENCY_AMOUNT = np.random.randint(1000, 100000)\n",
    "        self.USED_LEVERAGE = self.USED_CURRENCY_AMOUNT / self.OWN_CURRENCY_AMOUNT\n",
    "\n",
    "        #loss tollaranace is the 3%  of own currency amount\n",
    "        self.LOSS_TOLLARANCE = self.OWN_CURRENCY_AMOUNT * 0.03\n",
    "        \n",
    "        #accumulated loss tollarance is the 4%  of own currency amount\n",
    "        self.ACCUMULATED_LOSS_TOLLARANCE = self.OWN_CURRENCY_AMOUNT * 0.04\n",
    "        self.MINIMUM_GAINS = self.OWN_CURRENCY_AMOUNT * 0.05\n",
    "        self.MAXIMUM_DOING_NOTHING_STEPS_TOLLARANCE = 10\n",
    "        self.WRONG_STEPS_TOLLARANCE = 10\n",
    "        self.log_interval = 30  # Log every log_interval episodes   \n",
    "        self.taking_wrong_action_count = 0\n",
    "        self.auto_terminated_trades = 0\n",
    "        self.buy_open_uuids = {}\n",
    "        self.sell_open_uuids = {}        \n",
    "        self.previous_trade_details = {}\n",
    "        self.previous_reward = 0\n",
    "        self.net_gains = 0\n",
    "        self.current_step = 0\n",
    "        self.current_price = data['Close'][self.current_step]\n",
    "\n",
    "        # Action space:\n",
    "        # 0: buy\n",
    "        # 1: sel\n",
    "        # 2: buy close\n",
    "        # 3: sell close\n",
    "        # 4: hold\n",
    "        # 5: do nothing\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "\n",
    "        \n",
    "        # Observation space:\n",
    "        # 0: current price\n",
    "        # 1: own currency amount\n",
    "        # 2: used currency amount\n",
    "        # 3: used leverage\n",
    "        # 4: loss tollarance\n",
    "        # 5: accumulated loss tollarance\n",
    "        # 6: maximum amount of time for holding\n",
    "        # 7: current buy open trades\n",
    "        # 8: current sell open trades\n",
    "        # 9: auto terminated trades\n",
    "        # 10: maximum doing nothing steps tollarance\n",
    "        # 11: current step\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(12 ,), dtype=np.float32)\n",
    "    def calculate_buy_profit_loss(self, opening_price, closing_price, position_size, leverage):\n",
    "        # Calculate profit or loss based on opening and closing prices, position size, and leverage\n",
    "        profit_loss = ((closing_price - opening_price) / opening_price) * position_size * leverage\n",
    "        return profit_loss\n",
    "    \n",
    "    def calculate_sell_profit_loss(self, opening_price, closing_price, position_size, leverage):\n",
    "        # Calculate profit or loss based on opening and closing prices, position size, and leverage\n",
    "        profit_loss = ((opening_price - closing_price) / opening_price) * position_size * leverage\n",
    "        return profit_loss\n",
    "\n",
    "    def Terminate_lossing_buy_open_trades(self):\n",
    "        trades_to_close = []\n",
    "        for buy_open_uuid, trade_info in self.buy_open_uuids.items():\n",
    "            # Use calculate_buy_profit_loss function to calculate the profit or loss\n",
    "            if self.calculate_buy_profit_loss(trade_info['open_price'], self.current_price, self.OWN_CURRENCY_AMOUNT, self.USED_LEVERAGE) < self.LOSS_TOLLARANCE:\n",
    "                trades_to_close.append(buy_open_uuid)\n",
    "\n",
    "        for buy_open_uuid in trades_to_close:\n",
    "            self.close_trade(buy_open_uuid, self.buy_open_uuids, 'buy_open')\n",
    "            self.auto_terminated_trades += 1\n",
    "\n",
    "\n",
    "    def Terminate_lossing_sell_open_trades(self):\n",
    "        trades_to_close = []\n",
    "        for sell_open_uuid, trade_info in self.sell_open_uuids.items():\n",
    "            # Use calculate_sell_profit_loss function to calculate the profit or loss\n",
    "            if self.calculate_sell_profit_loss(trade_info['open_price'], self.current_price, self.OWN_CURRENCY_AMOUNT, self.USED_LEVERAGE) < self.LOSS_TOLLARANCE:\n",
    "                trades_to_close.append(sell_open_uuid)\n",
    "\n",
    "        for sell_open_uuid in trades_to_close:\n",
    "            self.close_trade(sell_open_uuid, self.sell_open_uuids, 'sell_open')\n",
    "            self.auto_terminated_trades += 1\n",
    "            \n",
    "    def Terminate_after_maximum_step(self):\n",
    "        if self.current_step > self.MAXIMUM_AMOUNT_OF_TIME_FOR_HOLDING:\n",
    "            # Make a copy of the dictionary keys before iterating\n",
    "\n",
    "            for buy_open_uuid in list(self.buy_open_uuids.keys()):\n",
    "                trade_info = self.buy_open_uuids[buy_open_uuid]\n",
    "                self.close_trade(buy_open_uuid, self.buy_open_uuids, 'buy_open')\n",
    "                self.auto_terminated_trades += 1\n",
    "                \n",
    "            for sell_open_uuid in list(self.sell_open_uuids.keys()):\n",
    "                trade_info = self.sell_open_uuids[sell_open_uuid]\n",
    "                self.close_trade(sell_open_uuid, self.sell_open_uuids, 'sell_open')\n",
    "                self.auto_terminated_trades += 1\n",
    "\n",
    "    def calculate_current_profit_loss(self):\n",
    "        # Calculate the current profit or loss\n",
    "        current_profit_loss = 0\n",
    "        for buy_open_uuid, trade_info in self.buy_open_uuids.items():\n",
    "            current_profit_loss += self.calculate_buy_profit_loss(trade_info['open_price'], self.current_price, self.OWN_CURRENCY_AMOUNT, self.USED_LEVERAGE)\n",
    "        for sell_open_uuid, trade_info in self.sell_open_uuids.items():\n",
    "            current_profit_loss += self.calculate_sell_profit_loss(trade_info['open_price'], self.current_price, self.OWN_CURRENCY_AMOUNT, self.USED_LEVERAGE)\n",
    "        return current_profit_loss\n",
    "\n",
    "            \n",
    "\n",
    "    def update_available_time_for_each_trade(self):\n",
    "        for buy_open_uuid, trade_info in self.buy_open_uuids.items():\n",
    "            trade_info['available_time'] -= 1\n",
    "            if trade_info['available_time'] == 0:\n",
    "                self.close_trade(buy_open_uuid, self.buy_open_uuids, 'buy_open')\n",
    "        for sell_open_uuid, trade_info in self.sell_open_uuids.items():\n",
    "            trade_info['available_time'] -= 1\n",
    "            if trade_info['available_time'] == 0:\n",
    "                self.close_trade(sell_open_uuid, self.sell_open_uuids, 'sell_open')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def close_trade(self, trade_uuid, trade_dict, trade_type):\n",
    "        trade_dict[trade_uuid]['close_price'] = self.current_price\n",
    "        if trade_type == 'buy_open':\n",
    "            self.net_gains += trade_dict[trade_uuid]['close_price'] - trade_dict[trade_uuid]['open_price']\n",
    "            self.current_buy_open_trades -= 1\n",
    "            #add to previous trade details\n",
    "            self.previous_trade_details[trade_uuid] = trade_dict[trade_uuid]\n",
    "            #fix currntt amount of money and leverage keep the used currency amount same\n",
    "            self.OWN_CURRENCY_AMOUNT += self.calculate_buy_profit_loss(trade_dict[trade_uuid]['open_price'], trade_dict[trade_uuid]['close_price'], self.OWN_CURRENCY_AMOUNT, self.USED_LEVERAGE)\n",
    "            self.USED_LEVERAGE = self.USED_CURRENCY_AMOUNT / self.OWN_CURRENCY_AMOUNT\n",
    "            self.LOSS_TOLLARANCE = self.OWN_CURRENCY_AMOUNT * 0.03\n",
    "\n",
    "\n",
    "\n",
    "        elif trade_type == 'sell_open':\n",
    "            self.net_gains += trade_dict[trade_uuid]['open_price'] - trade_dict[trade_uuid]['close_price']\n",
    "            self.current_sell_open_trades -= 1\n",
    "            #add to previous trade details\n",
    "            self.previous_trade_details[trade_uuid] = trade_dict[trade_uuid]\n",
    "            #fix currntt amount of money and leverage keep the used currency amount same\n",
    "            self.OWN_CURRENCY_AMOUNT += self.calculate_sell_profit_loss(trade_dict[trade_uuid]['open_price'], trade_dict[trade_uuid]['close_price'], self.OWN_CURRENCY_AMOUNT, self.USED_LEVERAGE)\n",
    "            self.USED_LEVERAGE = self.USED_CURRENCY_AMOUNT / self.OWN_CURRENCY_AMOUNT\n",
    "            self.LOSS_TOLLARANCE = self.OWN_CURRENCY_AMOUNT * 0.03\n",
    "\n",
    "\n",
    "        del trade_dict[trade_uuid]\n",
    "\n",
    "    def calculate_total_profit_loss(self):\n",
    "        #use previous and current trade details to calculate total profit loss\n",
    "        current_profit_loss = 0\n",
    "        for buy_open_uuid, trade_info in self.buy_open_uuids.items():\n",
    "            current_profit_loss += self.calculate_buy_profit_loss(trade_info['open_price'], self.current_price, self.OWN_CURRENCY_AMOUNT, self.USED_LEVERAGE)\n",
    "        for sell_open_uuid, trade_info in self.sell_open_uuids.items():\n",
    "            current_profit_loss += self.calculate_sell_profit_loss(trade_info['open_price'], self.current_price, self.OWN_CURRENCY_AMOUNT, self.USED_LEVERAGE)\n",
    "        previous_profit_loss = 0\n",
    "        for buy_open_uuid, trade_info in self.previous_trade_details.items():\n",
    "            previous_profit_loss += self.calculate_buy_profit_loss(trade_info['open_price'], trade_info['close_price'], self.OWN_CURRENCY_AMOUNT, self.USED_LEVERAGE)\n",
    "        for sell_open_uuid, trade_info in self.previous_trade_details.items():\n",
    "            previous_profit_loss += self.calculate_sell_profit_loss(trade_info['open_price'], trade_info['close_price'], self.OWN_CURRENCY_AMOUNT, self.USED_LEVERAGE)\n",
    "        total_profit_loss = current_profit_loss + previous_profit_loss\n",
    "        return total_profit_loss\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def calculate_number_of_profitable_trades(self):\n",
    "        profitable_trades = 0\n",
    "        for buy_open_uuid, trade_info in self.previous_trade_details.items():\n",
    "            if self.calculate_buy_profit_loss(trade_info['open_price'], trade_info['close_price'], self.OWN_CURRENCY_AMOUNT, self.USED_LEVERAGE) > 0:\n",
    "                profitable_trades += 1\n",
    "        for sell_open_uuid, trade_info in self.previous_trade_details.items():\n",
    "            if self.calculate_sell_profit_loss(trade_info['open_price'], trade_info['close_price'], self.OWN_CURRENCY_AMOUNT, self.USED_LEVERAGE) > 0:\n",
    "                profitable_trades += 1\n",
    "        return profitable_trades\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_number_of_total_trades_profotalbe_and_lossing_trades(self):\n",
    "        total_trades = len(self.previous_trade_details) + self.current_buy_open_trades + self.current_sell_open_trades\n",
    "        profitable_trades = self.calculate_number_of_profitable_trades()\n",
    "        lossing_trades = total_trades - profitable_trades\n",
    "        return total_trades, profitable_trades, lossing_trades\n",
    "\n",
    "\n",
    "    def reward(self,wrong_action:bool = False,do_nothing:bool = False,done:bool = False):\n",
    "        # 1) reward is proportional to the profit or loss\n",
    "        # 2) reward is proportional to the number of trades\n",
    "        # 4) reward is inversely proportional to number of auto terminated trades\n",
    "        # 5)panalty for doing nothing\n",
    "        # 6) reward for closing profitable trades\n",
    "        # 7) panalty for closing lossing trades\n",
    "        # 8) extra reward for each 2% profit\n",
    "        # 9) i step == 404 then means done and panalty\n",
    "        # 10)  if current reward is more than previous reward then reward is positive else negative\n",
    "        # 11) panalty for done\n",
    "        total_profit_loss = self.calculate_total_profit_loss() \n",
    "        current_profit_loss = self.calculate_current_profit_loss()\n",
    "\n",
    "        total_profit_loss_percentage = (total_profit_loss / self.OWN_CURRENCY_AMOUNT) * 100\n",
    "        current_profit_loss_percentage = (current_profit_loss / self.OWN_CURRENCY_AMOUNT) * 100\n",
    "\n",
    "        current_number_of_open_trade = self.current_buy_open_trades + self.current_sell_open_trades\n",
    "        auto_terminated_trades = self.auto_terminated_trades\n",
    "        total_trades, profitable_trades, lossing_trades = self.calculate_number_of_total_trades_profotalbe_and_lossing_trades()\n",
    "        profit_loss_percentage = total_profit_loss / self.OWN_CURRENCY_AMOUNT            \n",
    "        K = 0.1  # You can adjust this value based on the desired magnitude of the rewards/penalties\n",
    "\n",
    "        reward = (\n",
    "            K * total_profit_loss_percentage +                  # Reward proportional to profit or loss\n",
    "            K * current_profit_loss_percentage +                # Reward proportional to profit or loss\n",
    "            K * total_trades +                       # Reward proportional to the number of trades\n",
    "            -K * auto_terminated_trades +            # Penalty inversely proportional to the number of auto-terminated trades\n",
    "            -K * (not current_profit_loss) +  # Penalty for doing nothing\n",
    "            K * profitable_trades +                  # Reward for closing profitable trades\n",
    "            -K * lossing_trades +               \n",
    "                 \n",
    "                 \n",
    "                      # Penalty for closing losing trades\n",
    "            K * (\n",
    "                \n",
    "                \n",
    "                \n",
    "                   profit_loss_percentage // 0.02)     # Extra reward for each 2% profit\n",
    "        )\n",
    "        reward= reward + K * (1 if reward > self.previous_reward else -1)  # Reward for improving or penalizing the reward\n",
    "\n",
    "        if wrong_action:\n",
    "            reward = -K * 10\n",
    "            self.WRONG_STEPS_TOLLARANCE -= 1\n",
    "        if done:\n",
    "            reward = -K * 100\n",
    "\n",
    "        if self.previous_reward == 0:\n",
    "            self.previous_reward = reward\n",
    "            reward = 0.00000\n",
    "        else:\n",
    "            previous_reward = reward\n",
    "            reward = reward - self.previous_reward\n",
    "            self.previous_reward = previous_reward\n",
    "        \n",
    "\n",
    "        return reward\n",
    "    \n",
    "\n",
    "    def reset(self, new_data=None):\n",
    "        self.current_step = 0\n",
    "        self.current_price = self.data['Close'][self.current_step]\n",
    "        self.current_buy_open_trades = 0\n",
    "        self.current_sell_open_trades = 0\n",
    "        self.auto_terminated_trades = 0\n",
    "        self.buy_open_uuids = {}\n",
    "        self.sell_open_uuids = {}\n",
    "        self.previous_trade_details = {}\n",
    "        self.previous_reward = 0\n",
    "        self.net_gains = 0\n",
    "        self.MAXIMUM_DOING_NOTHING_STEPS_TOLLARANCE = 10\n",
    "\n",
    "        # Reset currency amounts\n",
    "        self.OWN_CURRENCY_AMOUNT = np.random.randint(10, 100)\n",
    "        self.USED_CURRENCY_AMOUNT = np.random.randint(1000, 100000)\n",
    "        self.USED_LEVERAGE = self.USED_CURRENCY_AMOUNT / self.OWN_CURRENCY_AMOUNT\n",
    "        self.LOSS_TOLLARANCE = self.OWN_CURRENCY_AMOUNT * 0.03\n",
    "        self.ACCUMULATED_LOSS_TOLLARANCE = self.OWN_CURRENCY_AMOUNT * 0.1\n",
    "\n",
    "        # Reset maximum steps for holding\n",
    "        self.MAXIMUM_AMOUNT_OF_TIME_FOR_HOLDING = 100\n",
    "\n",
    "        # Reset initial step conditions\n",
    "        self.current_price = self.data['Close'][self.current_step]\n",
    "\n",
    "        # Reset action and observation spaces\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(12 ,), dtype=np.float32)\n",
    "        \n",
    "        # Reset the environment and return the initial observation\n",
    "        obs = self._next_observation()\n",
    "        return obs\n",
    "    \n",
    "    def _next_observation(self):\n",
    "        obs = np.array([\n",
    "            self.current_price,\n",
    "            self.OWN_CURRENCY_AMOUNT,\n",
    "            self.USED_CURRENCY_AMOUNT,\n",
    "            self.USED_LEVERAGE,\n",
    "            self.LOSS_TOLLARANCE,\n",
    "            self.ACCUMULATED_LOSS_TOLLARANCE,\n",
    "            self.MAXIMUM_AMOUNT_OF_TIME_FOR_HOLDING,\n",
    "            self.current_buy_open_trades,\n",
    "            self.current_sell_open_trades,\n",
    "            self.auto_terminated_trades,\n",
    "            self.MAXIMUM_DOING_NOTHING_STEPS_TOLLARANCE,\n",
    "            self.current_step\n",
    "\n",
    "        ])\n",
    "        \n",
    "        return obs\n",
    "\n",
    "    def step(self, action ):\n",
    "        self.current_step += 1.\n",
    "        self.current_price = self.data['Close'][self.current_step]\n",
    "        self.Terminate_after_maximum_step()\n",
    "        self.Terminate_lossing_buy_open_trades()\n",
    "        self.Terminate_lossing_sell_open_trades()\n",
    "        self.current_buy_open_trades = len(self.buy_open_uuids)\n",
    "        self.current_sell_open_trades = len(self.sell_open_uuids)\n",
    "        total_open_trades = self.current_buy_open_trades + self.current_sell_open_trades\n",
    "        wrong_action = False\n",
    "        do_nothing = False\n",
    "\n",
    "        if action == 0:\n",
    "            if total_open_trades == 0:\n",
    "                self.buy_open_uuids[str(uuid.uuid4())] = {\n",
    "                    'open_price': self.current_price,\n",
    "                    'available_time': self.MAXIMUM_AMOUNT_OF_TIME_FOR_HOLDING\n",
    "                }\n",
    "            else:\n",
    "                action = 4\n",
    "                self.taking_wrong_action_count += 1\n",
    "                wrong_action = True\n",
    "        elif action == 1:\n",
    "            if total_open_trades == 0:\n",
    "                self.sell_open_uuids[str(uuid.uuid4())] = {\n",
    "                    'open_price': self.current_price,\n",
    "                    'available_time': self.MAXIMUM_AMOUNT_OF_TIME_FOR_HOLDING\n",
    "                }\n",
    "            else:\n",
    "                action = 4\n",
    "                self.taking_wrong_action_count += 1\n",
    "                wrong_action = True\n",
    "        elif action == 2:\n",
    "            if self.current_buy_open_trades > 0:\n",
    "                buy_open_uuid = list(self.buy_open_uuids.keys())[0]\n",
    "                self.close_trade(buy_open_uuid, self.buy_open_uuids, 'buy_open')\n",
    "            elif self.current_sell_open_trades > 0:\n",
    "                action = 4 # Hold\n",
    "                self.taking_wrong_action_count += 1\n",
    "                wrong_action = True\n",
    "            else:\n",
    "                action = 5 # Do nothing\n",
    "                self.taking_wrong_action_count += 1\n",
    "                wrong_action = True\n",
    "                self.MAXIMUM_DOING_NOTHING_STEPS_TOLLARANCE -= 1\n",
    "                do_nothing = True\n",
    "            \n",
    "        elif action == 3:\n",
    "            if self.current_sell_open_trades > 0:\n",
    "                sell_open_uuid = list(self.sell_open_uuids.keys())[0]\n",
    "                self.close_trade(sell_open_uuid, self.sell_open_uuids, 'sell_open')\n",
    "            elif self.current_buy_open_trades > 0:\n",
    "                action = 4\n",
    "                self.taking_wrong_action_count += 1\n",
    "                wrong_action = True\n",
    "            else:\n",
    "                action = 5 # Do nothing\n",
    "                self.taking_wrong_action_count += 1\n",
    "                wrong_action = True\n",
    "                self.MAXIMUM_DOING_NOTHING_STEPS_TOLLARANCE -= 1\n",
    "                do_nothing = True\n",
    "\n",
    "        elif action == 4:\n",
    "            if total_open_trades == 0:\n",
    "                action = 5\n",
    "                self.taking_wrong_action_count += 1\n",
    "                wrong_action = True\n",
    "            else:\n",
    "                action = 4\n",
    "        elif action == 5:\n",
    "            if total_open_trades > 0:\n",
    "                action = 4\n",
    "                self.taking_wrong_action_count += 1\n",
    "                wrong_action = True\n",
    "            else:\n",
    "                action = 5\n",
    "                self.MAXIMUM_DOING_NOTHING_STEPS_TOLLARANCE -= 1\n",
    "                do_nothing = True\n",
    "            \n",
    "        else:\n",
    "            action = 5\n",
    "            self.taking_wrong_action_count += 1\n",
    "            wrong_action = True\n",
    "            self.MAXIMUM_DOING_NOTHING_STEPS_TOLLARANCE -= 1\n",
    "            do_nothing = True\n",
    "\n",
    "\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        done = self.done()\n",
    "        reward = self.reward(wrong_action,do_nothing,done)\n",
    "\n",
    "        info = {'action':action,'current_price': self.current_price, 'current_step': self.current_step, 'current_profit_loss': self.calculate_current_profit_loss(), 'total_profit_loss': self.calculate_total_profit_loss(), 'net_gains': self.net_gains, 'current_buy_open_trades': self.current_buy_open_trades, 'current_sell_open_trades': self.current_sell_open_trades, 'auto_terminated_trades': self.auto_terminated_trades, 'previous_reward': self.previous_reward, 'buy_open_uuids': self.buy_open_uuids, 'sell_open_uuids': self.sell_open_uuids, 'previous_trade_details': self.previous_trade_details}      \n",
    "\n",
    "        #if done then add to tensorboard\n",
    "        if done:\n",
    "            self.log_to_tensorboard(reward)\n",
    "        \n",
    "        return obs, reward, done, info\n",
    "\n",
    "\n",
    "\n",
    "    def done(self):\n",
    "    #1)if current loss is greater than 3% of own currency amount\n",
    "    #2)if auto terminated trades are greater than 3\n",
    "    #3)if all comolative loss is greater than 10% of own currency amount\n",
    "    #4)maximum doing nothing steps tollarance\n",
    "    #5) IF 3 loss trades over 10 trades and 2 consecutive loss trades\n",
    "    #6) if maximum doing nothing steps tollarance is 0\n",
    "    #7) if total rades are 3 or more but cutent totatal profit is less than 10% of own currency amount\n",
    "        current_profit_loss = self.calculate_current_profit_loss()\n",
    "        # print(\"current loss is \", current_profit_loss)\n",
    "        # print(\"loss tollarance is \", self.LOSS_TOLLARANCE)\n",
    "        # print(\"accumulated loss tollarance is \", self.ACCUMULATED_LOSS_TOLLARANCE)\n",
    "\n",
    "\n",
    "        autoterminated_trades = self.auto_terminated_trades\n",
    "        cumulative_profit_loss = self.calculate_total_profit_loss()\n",
    "        doing_nothing_steps_tollarance = self.MAXIMUM_DOING_NOTHING_STEPS_TOLLARANCE\n",
    "        total_trades, profitable_trades, lossing_trades = self.calculate_number_of_total_trades_profotalbe_and_lossing_trades()\n",
    "        wrong_steps_tollarance = self.WRONG_STEPS_TOLLARANCE\n",
    "\n",
    "        \n",
    "        if current_profit_loss < -self.LOSS_TOLLARANCE:\n",
    "            \n",
    "            return True\n",
    "        elif autoterminated_trades > 2:\n",
    "            \n",
    "            return True\n",
    "        elif cumulative_profit_loss < -self.ACCUMULATED_LOSS_TOLLARANCE:\n",
    "            \n",
    "            return True\n",
    "        elif doing_nothing_steps_tollarance == 0:\n",
    "            \n",
    "            return True\n",
    "        elif wrong_steps_tollarance == 0:\n",
    "            \n",
    "            return True\n",
    "        elif lossing_trades > 2 and lossing_trades / total_trades > 0.3:\n",
    "            \n",
    "            return True\n",
    "        elif total_trades >= 4 and cumulative_profit_loss < self.MINIMUM_GAINS:\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        profit_loss = self.calculate_total_profit_loss()\n",
    "        print(f'Step: {self.current_step}')\n",
    "        print(f'Price: {self.current_price}')\n",
    "        print(f'Profit/Loss: {profit_loss}')\n",
    "        print(f'Net Gains: {self.net_gains}')\n",
    "        print(f'Current Buy Open Trades: {self.current_buy_open_trades}')\n",
    "        print(f'Current Sell Open Trades: {self.current_sell_open_trades}')\n",
    "        print(f'Auto Terminated Trades: {self.auto_terminated_trades}')\n",
    "        print(f'Previous Reward: {self.previous_reward}')\n",
    "        print(f'Action Space: {self.action_space}')\n",
    "        print(f'Observation Space: {self.observation_space}')\n",
    "        print(f'Buy Open Trades: {self.buy_open_uuids}')\n",
    "        print(f'Sell Open Trades: {self.sell_open_uuids}')\n",
    "        print(f'Previous Trade Details: {self.previous_trade_details}')\n",
    "\n",
    "\n",
    "\n",
    "    def log_to_tensorboard(self, reward):\n",
    "        # Log relevant metrics to TensorBoard\n",
    "        self.current_buy_open_trades = len(self.buy_open_uuids)\n",
    "        self.current_sell_open_trades = len(self.sell_open_uuids)\n",
    "        total_open_trades = self.current_buy_open_trades + self.current_sell_open_trades\n",
    "    \n",
    "        self.writer.add_scalar(\"Reward\", reward, self.current_step)\n",
    "        self.writer.add_scalar(\"Profit/Loss\", self.calculate_total_profit_loss(), self.current_step)\n",
    "        self.writer.add_scalar(\"Net Gains\", self.net_gains, self.current_step)\n",
    "        self.writer.add_scalar(\"Auto Terminated Trades\", self.auto_terminated_trades, self.current_step)\n",
    "        self.writer.add_scalar(\"Previous Reward\", self.previous_reward, self.current_step)\n",
    "        self.writer.add_scalar(\"Current Step\", self.current_step, self.current_step)\n",
    "        self.writer.add_scalar(\"current profit loss\", self.calculate_current_profit_loss(), self.current_step)\n",
    "        self.writer.add_scalar(\"total trades\", total_open_trades, self.current_step)\n",
    "        self.writer.add_scalar(\"number of profitable trades\", self.calculate_number_of_profitable_trades(), self.current_step)\n",
    "        self.writer.add_scalar(\"number of lossing trades\", total_open_trades - self.calculate_number_of_profitable_trades(), self.current_step)\n",
    "        self.writer.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Demo_4M.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the frame skip frequency\n",
    "frame_skip_frequency = 1\n",
    "\n",
    "# Define the number of training steps\n",
    "total_timesteps = 1000000\n",
    "\n",
    "# Define the directory paths\n",
    "LOG_DIR = './logs/'\n",
    "OPT_DIR = './opt_modeldata/'\n",
    "CHECKPOINT_DIR = './train_modeldata/'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(OPT_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(6)\n",
      "Observation space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 4.40000000e+01 2.66570000e+04 6.05840909e+02\n",
      " 1.32000000e+00 4.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 4.40000000e+01 2.66570000e+04 6.05840909e+02\n",
      " 1.32000000e+00 4.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 8.00000000e+00 2.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 4.40000000e+01 2.66570000e+04 6.05840909e+02\n",
      " 1.32000000e+00 4.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 8.00000000e+00 3.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 4.40000000e+01 2.66570000e+04 6.05840909e+02\n",
      " 1.32000000e+00 4.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.00000000e+00 4.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 4.40000000e+01 2.66570000e+04 6.05840909e+02\n",
      " 1.32000000e+00 4.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 6.00000000e+00 5.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -0.2\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'55f4f7eb-a8ac-4444-a07e-503f943d35af': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 4.40000000e+01 2.66570000e+04 6.05840909e+02\n",
      " 1.32000000e+00 4.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 6.00000000e+00 6.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -0.2, 'buy_open_uuids': {}, 'sell_open_uuids': {'55f4f7eb-a8ac-4444-a07e-503f943d35af': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.30000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'e147e53d-e0cd-4bdc-83cf-20a141e4894f': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'55f4f7eb-a8ac-4444-a07e-503f943d35af': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 4.40000000e+01 2.66570000e+04 6.05840909e+02\n",
      " 1.32000000e+00 4.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 6.00000000e+00 7.00000000e+00] reward= -0.10000000000000003 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.30000000000000004, 'buy_open_uuids': {'e147e53d-e0cd-4bdc-83cf-20a141e4894f': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'55f4f7eb-a8ac-4444-a07e-503f943d35af': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.4\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'a7dee3ec-d4f3-4d93-892b-2be4db32c048': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'55f4f7eb-a8ac-4444-a07e-503f943d35af': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'e147e53d-e0cd-4bdc-83cf-20a141e4894f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 4.40000000e+01 2.66570000e+04 6.05840909e+02\n",
      " 1.32000000e+00 4.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 6.00000000e+00 8.00000000e+00] reward= -0.09999999999999998 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.4, 'buy_open_uuids': {'a7dee3ec-d4f3-4d93-892b-2be4db32c048': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'55f4f7eb-a8ac-4444-a07e-503f943d35af': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'e147e53d-e0cd-4bdc-83cf-20a141e4894f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 9.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'55f4f7eb-a8ac-4444-a07e-503f943d35af': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'e147e53d-e0cd-4bdc-83cf-20a141e4894f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'a7dee3ec-d4f3-4d93-892b-2be4db32c048': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 4.40000000e+01 2.66570000e+04 6.05840909e+02\n",
      " 1.32000000e+00 4.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 3.00000000e+00 5.00000000e+00 9.00000000e+00] reward= -9.6 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 9.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'55f4f7eb-a8ac-4444-a07e-503f943d35af': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'e147e53d-e0cd-4bdc-83cf-20a141e4894f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'a7dee3ec-d4f3-4d93-892b-2be4db32c048': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 3.10000000e+01 1.60020000e+04 5.16193548e+02\n",
      " 9.30000000e-01 3.10000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 3.10000000e+01 1.60020000e+04 5.16193548e+02\n",
      " 9.30000000e-01 3.10000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 8.00000000e+00 2.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -0.2\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 3.10000000e+01 1.60020000e+04 5.16193548e+02\n",
      " 9.30000000e-01 3.10000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.00000000e+00 3.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -0.2, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 3.10000000e+01 1.60020000e+04 5.16193548e+02\n",
      " 9.30000000e-01 3.10000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.00000000e+00 4.00000000e+00] reward= 0.2 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {}, 'sell_open_uuids': {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.30000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.10000000e+01 1.60020000e+04 5.16193548e+02\n",
      " 9.30000000e-01 3.10000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 7.00000000e+00 5.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.30000000000000004, 'buy_open_uuids': {'7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.10000000e+01 1.60020000e+04 5.16193548e+02\n",
      " 9.30000000e-01 3.10000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 6.00000000e+00 6.00000000e+00] reward= -0.7 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.10000000e+01 1.60020000e+04 5.16193548e+02\n",
      " 9.30000000e-01 3.10000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 6.00000000e+00 7.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.10000000e+01 1.60020000e+04 5.16193548e+02\n",
      " 9.30000000e-01 3.10000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 5.00000000e+00 8.00000000e+00] reward= 0.7999999999999999 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 9.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.10000000e+01 1.60020000e+04 5.16193548e+02\n",
      " 9.30000000e-01 3.10000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 5.00000000e+00 9.00000000e+00] reward= -0.7999999999999999 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 9.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 10.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'602bb682-0814-4f80-8f55-8fe341806ca0': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.10000000e+01 1.60020000e+04 5.16193548e+02\n",
      " 9.30000000e-01 3.10000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 5.00000000e+00 1.00000000e+01] reward= 0.7999999999999999 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 10.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {'602bb682-0814-4f80-8f55-8fe341806ca0': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 11.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 1\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'5d19262d-3035-4306-ab2c-d4ace63dc039': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '602bb682-0814-4f80-8f55-8fe341806ca0': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.10000000e+01 1.60020000e+04 5.16193548e+02\n",
      " 9.30000000e-01 3.10000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 3.00000000e+00 5.00000000e+00 1.10000000e+01] reward= -9.8 done= True\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 11.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {'5d19262d-3035-4306-ab2c-d4ace63dc039': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'ce940e37-15b0-42df-a688-282445093bda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7089994f-722d-4350-aaf3-1eb0a136482f': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '602bb682-0814-4f80-8f55-8fe341806ca0': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 2.90000000e+01 9.18400000e+03 3.16689655e+02\n",
      " 8.70000000e-01 2.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+01 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 2.90000000e+01 9.18400000e+03 3.16689655e+02\n",
      " 8.70000000e-01 2.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+01 2.00000000e+00] reward= -9.0 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 3.00000000e+01 5.10910000e+04 1.70303333e+03\n",
      " 9.00000000e-01 3.00000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+01 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'6a7e8883-e13c-46ea-bd87-509589f7302d': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 3.00000000e+01 5.10910000e+04 1.70303333e+03\n",
      " 9.00000000e-01 3.00000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+01 2.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {'6a7e8883-e13c-46ea-bd87-509589f7302d': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'6a7e8883-e13c-46ea-bd87-509589f7302d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.00000000e+01 5.10910000e+04 1.70303333e+03\n",
      " 9.00000000e-01 3.00000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.00000000e+00 3.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'6a7e8883-e13c-46ea-bd87-509589f7302d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'6a7e8883-e13c-46ea-bd87-509589f7302d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.00000000e+01 5.10910000e+04 1.70303333e+03\n",
      " 9.00000000e-01 3.00000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 8.00000000e+00 4.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'6a7e8883-e13c-46ea-bd87-509589f7302d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'9781fc39-71ed-4d3f-a43a-fccae07cdac1': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'6a7e8883-e13c-46ea-bd87-509589f7302d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.00000000e+01 5.10910000e+04 1.70303333e+03\n",
      " 9.00000000e-01 3.00000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 8.00000000e+00 5.00000000e+00] reward= 0.9 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {}, 'sell_open_uuids': {'9781fc39-71ed-4d3f-a43a-fccae07cdac1': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'6a7e8883-e13c-46ea-bd87-509589f7302d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.4\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'95310c42-2560-430c-85d6-e7ba71a3413d': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'6a7e8883-e13c-46ea-bd87-509589f7302d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '9781fc39-71ed-4d3f-a43a-fccae07cdac1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.00000000e+01 5.10910000e+04 1.70303333e+03\n",
      " 9.00000000e-01 3.00000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 6.00000000e+00] reward= -0.30000000000000004 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.4, 'buy_open_uuids': {'95310c42-2560-430c-85d6-e7ba71a3413d': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'6a7e8883-e13c-46ea-bd87-509589f7302d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '9781fc39-71ed-4d3f-a43a-fccae07cdac1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'6a7e8883-e13c-46ea-bd87-509589f7302d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '9781fc39-71ed-4d3f-a43a-fccae07cdac1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '95310c42-2560-430c-85d6-e7ba71a3413d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.00000000e+01 5.10910000e+04 1.70303333e+03\n",
      " 9.00000000e-01 3.00000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 3.00000000e+00 7.00000000e+00 7.00000000e+00] reward= -9.6 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'6a7e8883-e13c-46ea-bd87-509589f7302d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '9781fc39-71ed-4d3f-a43a-fccae07cdac1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '95310c42-2560-430c-85d6-e7ba71a3413d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 1.70000000e+01 2.41530000e+04 1.42076471e+03\n",
      " 5.10000000e-01 1.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 1.70000000e+01 2.41530000e+04 1.42076471e+03\n",
      " 5.10000000e-01 1.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 8.00000000e+00 2.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 1.70000000e+01 2.41530000e+04 1.42076471e+03\n",
      " 5.10000000e-01 1.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.00000000e+00 3.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 1.70000000e+01 2.41530000e+04 1.42076471e+03\n",
      " 5.10000000e-01 1.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.00000000e+00 4.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {}, 'sell_open_uuids': {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.30000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 1.70000000e+01 2.41530000e+04 1.42076471e+03\n",
      " 5.10000000e-01 1.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 6.00000000e+00 5.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.30000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 1.70000000e+01 2.41530000e+04 1.42076471e+03\n",
      " 5.10000000e-01 1.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 5.00000000e+00 6.00000000e+00] reward= -0.7 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 1.70000000e+01 2.41530000e+04 1.42076471e+03\n",
      " 5.10000000e-01 1.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 4.00000000e+00 7.00000000e+00] reward= 0.9 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 1.70000000e+01 2.41530000e+04 1.42076471e+03\n",
      " 5.10000000e-01 1.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 3.00000000e+00 8.00000000e+00] reward= -0.9 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 9.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 1.70000000e+01 2.41530000e+04 1.42076471e+03\n",
      " 5.10000000e-01 1.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 2.00000000e+00 9.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 9.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 10.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 1.70000000e+01 2.41530000e+04 1.42076471e+03\n",
      " 5.10000000e-01 1.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+01] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 10.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 11.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 1.70000000e+01 2.41530000e+04 1.42076471e+03\n",
      " 5.10000000e-01 1.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 0.00000000e+00 1.10000000e+01] reward= -9.0 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 11.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1e319c2e-5685-4d04-ab3b-a6a587245891': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+01 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 2.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 3.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 8.00000000e+00 4.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.00000000e+00 5.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 7.00000000e+00 6.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 6.00000000e+00 7.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 5.00000000e+00 8.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 9.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 5.00000000e+00 9.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 9.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 10.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 4.00000000e+00 1.00000000e+01] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 10.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 11.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 3.00000000e+00 1.10000000e+01] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 11.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 12.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'23997b53-5c11-4b3a-be51-be4a097af624': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 3.00000000e+00 1.20000000e+01] reward= 0.9 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 12.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {}, 'sell_open_uuids': {'23997b53-5c11-4b3a-be51-be4a097af624': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 13.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '23997b53-5c11-4b3a-be51-be4a097af624': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 2.00000000e+00 1.30000000e+01] reward= -0.9 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 13.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '23997b53-5c11-4b3a-be51-be4a097af624': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 14.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '23997b53-5c11-4b3a-be51-be4a097af624': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 1.00000000e+00 1.40000000e+01] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 14.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '23997b53-5c11-4b3a-be51-be4a097af624': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 15.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '23997b53-5c11-4b3a-be51-be4a097af624': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 7.60000000e+01 4.08610000e+04 5.37644737e+02\n",
      " 2.28000000e+00 7.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 0.00000000e+00 1.50000000e+01] reward= -9.0 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 15.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'9fe84575-bd76-4f77-89b2-c3ea5cc028f1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '23997b53-5c11-4b3a-be51-be4a097af624': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 6.90000000e+01 4.67300000e+04 6.77246377e+02\n",
      " 2.07000000e+00 6.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 6.90000000e+01 4.67300000e+04 6.77246377e+02\n",
      " 2.07000000e+00 6.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 2.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.90000000e+01 4.67300000e+04 6.77246377e+02\n",
      " 2.07000000e+00 6.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 8.00000000e+00 3.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.90000000e+01 4.67300000e+04 6.77246377e+02\n",
      " 2.07000000e+00 6.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 7.00000000e+00 4.00000000e+00] reward= 0.9 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.30000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.90000000e+01 4.67300000e+04 6.77246377e+02\n",
      " 2.07000000e+00 6.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 6.00000000e+00 5.00000000e+00] reward= -0.20000000000000004 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.30000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'1e55a523-a096-4686-acc1-5bc51fbbd4b7': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.90000000e+01 4.67300000e+04 6.77246377e+02\n",
      " 2.07000000e+00 6.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 6.00000000e+00 6.00000000e+00] reward= 0.20000000000000004 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {'1e55a523-a096-4686-acc1-5bc51fbbd4b7': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '1e55a523-a096-4686-acc1-5bc51fbbd4b7': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.90000000e+01 4.67300000e+04 6.77246377e+02\n",
      " 2.07000000e+00 6.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 5.00000000e+00 7.00000000e+00] reward= -0.9 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '1e55a523-a096-4686-acc1-5bc51fbbd4b7': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '1e55a523-a096-4686-acc1-5bc51fbbd4b7': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.90000000e+01 4.67300000e+04 6.77246377e+02\n",
      " 2.07000000e+00 6.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 4.00000000e+00 8.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '1e55a523-a096-4686-acc1-5bc51fbbd4b7': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 9.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'f907c092-5a21-4e39-8a5c-72b45a022085': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '1e55a523-a096-4686-acc1-5bc51fbbd4b7': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.90000000e+01 4.67300000e+04 6.77246377e+02\n",
      " 2.07000000e+00 6.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 4.00000000e+00 9.00000000e+00] reward= 0.7999999999999999 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 9.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {'f907c092-5a21-4e39-8a5c-72b45a022085': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '1e55a523-a096-4686-acc1-5bc51fbbd4b7': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 10.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '1e55a523-a096-4686-acc1-5bc51fbbd4b7': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'f907c092-5a21-4e39-8a5c-72b45a022085': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.90000000e+01 4.67300000e+04 6.77246377e+02\n",
      " 2.07000000e+00 6.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 3.00000000e+00 3.00000000e+00 1.00000000e+01] reward= -9.8 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 10.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'3e00c05c-8361-49e0-a168-cc59ee99a117': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '1e55a523-a096-4686-acc1-5bc51fbbd4b7': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'f907c092-5a21-4e39-8a5c-72b45a022085': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -0.2\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 9.90000000e+01 2.48380000e+04 2.50888889e+02\n",
      " 2.97000000e+00 9.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+01 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -0.2, 'buy_open_uuids': {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 9.90000000e+01 2.48380000e+04 2.50888889e+02\n",
      " 2.97000000e+00 9.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.00000000e+00 2.00000000e+00] reward= -0.8 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'82095979-ef42-475e-a170-f235f0faa652': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 9.90000000e+01 2.48380000e+04 2.50888889e+02\n",
      " 2.97000000e+00 9.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.00000000e+00 3.00000000e+00] reward= 0.9 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {'82095979-ef42-475e-a170-f235f0faa652': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '82095979-ef42-475e-a170-f235f0faa652': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 9.90000000e+01 2.48380000e+04 2.50888889e+02\n",
      " 2.97000000e+00 9.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 4.00000000e+00] reward= -0.9 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '82095979-ef42-475e-a170-f235f0faa652': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '82095979-ef42-475e-a170-f235f0faa652': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 9.90000000e+01 2.48380000e+04 2.50888889e+02\n",
      " 2.97000000e+00 9.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 5.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '82095979-ef42-475e-a170-f235f0faa652': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'f15df982-64af-4756-a045-49e5300381ee': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '82095979-ef42-475e-a170-f235f0faa652': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 9.90000000e+01 2.48380000e+04 2.50888889e+02\n",
      " 2.97000000e+00 9.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 6.00000000e+00] reward= 0.7999999999999999 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {'f15df982-64af-4756-a045-49e5300381ee': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '82095979-ef42-475e-a170-f235f0faa652': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 1\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'6f3ea028-7d17-4098-9e60-0fb3c14c7373': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '82095979-ef42-475e-a170-f235f0faa652': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'f15df982-64af-4756-a045-49e5300381ee': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 9.90000000e+01 2.48380000e+04 2.50888889e+02\n",
      " 2.97000000e+00 9.90000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 3.00000000e+00 8.00000000e+00 7.00000000e+00] reward= -9.8 done= True\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {'6f3ea028-7d17-4098-9e60-0fb3c14c7373': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'38081100-ef1b-4045-a01b-4364a3798fc5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '82095979-ef42-475e-a170-f235f0faa652': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'f15df982-64af-4756-a045-49e5300381ee': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -0.2\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.0645e+00 2.5000e+01 2.1854e+04 8.7416e+02 7.5000e-01 2.5000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+01 1.0000e+00] reward= 0.0 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -0.2, 'buy_open_uuids': {}, 'sell_open_uuids': {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 2.5000e+01 2.1854e+04 8.7416e+02 7.5000e-01 2.5000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 1.0000e+00 1.0000e+01 2.0000e+00] reward= -0.8 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 2.5000e+01 2.1854e+04 8.7416e+02 7.5000e-01 2.5000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 1.0000e+00 9.0000e+00 3.0000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 2.5000e+01 2.1854e+04 8.7416e+02 7.5000e-01 2.5000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 1.0000e+00 8.0000e+00 4.0000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'ae0b2872-8058-4f55-8877-ced2de033d79': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 2.5000e+01 2.1854e+04 8.7416e+02 7.5000e-01 2.5000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 1.0000e+00 8.0000e+00 5.0000e+00] reward= 0.9 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {}, 'sell_open_uuids': {'ae0b2872-8058-4f55-8877-ced2de033d79': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ae0b2872-8058-4f55-8877-ced2de033d79': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 2.5000e+01 2.1854e+04 8.7416e+02 7.5000e-01 2.5000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 2.0000e+00 8.0000e+00 6.0000e+00] reward= -0.9 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ae0b2872-8058-4f55-8877-ced2de033d79': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'63c06575-d37c-4ad8-bedf-366f840a44a1': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ae0b2872-8058-4f55-8877-ced2de033d79': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 2.5000e+01 2.1854e+04 8.7416e+02 7.5000e-01 2.5000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 2.0000e+00 8.0000e+00 7.0000e+00] reward= 0.7999999999999999 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {'63c06575-d37c-4ad8-bedf-366f840a44a1': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ae0b2872-8058-4f55-8877-ced2de033d79': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ae0b2872-8058-4f55-8877-ced2de033d79': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '63c06575-d37c-4ad8-bedf-366f840a44a1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 2.5000e+01 2.1854e+04 8.7416e+02 7.5000e-01 2.5000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 3.0000e+00 7.0000e+00 8.0000e+00] reward= -9.8 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'716387b0-35fa-499a-885c-45f4b8d5970b': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ae0b2872-8058-4f55-8877-ced2de033d79': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '63c06575-d37c-4ad8-bedf-366f840a44a1': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 4.60000000e+01 6.95780000e+04 1.51256522e+03\n",
      " 1.38000000e+00 4.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+01 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 4.60000000e+01 6.95780000e+04 1.51256522e+03\n",
      " 1.38000000e+00 4.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 2.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 4.60000000e+01 6.95780000e+04 1.51256522e+03\n",
      " 1.38000000e+00 4.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 3.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'fb206851-8d39-435c-a61d-4ba69d530516': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 4.60000000e+01 6.95780000e+04 1.51256522e+03\n",
      " 1.38000000e+00 4.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 4.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {}, 'sell_open_uuids': {'fb206851-8d39-435c-a61d-4ba69d530516': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.30000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'4102c4d0-1943-419c-ac6b-a334d55523c8': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'fb206851-8d39-435c-a61d-4ba69d530516': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 4.60000000e+01 6.95780000e+04 1.51256522e+03\n",
      " 1.38000000e+00 4.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.00000000e+00 5.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.30000000000000004, 'buy_open_uuids': {'4102c4d0-1943-419c-ac6b-a334d55523c8': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'fb206851-8d39-435c-a61d-4ba69d530516': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.4\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'fb206851-8d39-435c-a61d-4ba69d530516': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '4102c4d0-1943-419c-ac6b-a334d55523c8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 4.60000000e+01 6.95780000e+04 1.51256522e+03\n",
      " 1.38000000e+00 4.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 6.00000000e+00] reward= -0.09999999999999998 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.4, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'fb206851-8d39-435c-a61d-4ba69d530516': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '4102c4d0-1943-419c-ac6b-a334d55523c8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'1f1319cd-9f41-4509-8ce6-56371750c4fd': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'fb206851-8d39-435c-a61d-4ba69d530516': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '4102c4d0-1943-419c-ac6b-a334d55523c8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 4.60000000e+01 6.95780000e+04 1.51256522e+03\n",
      " 1.38000000e+00 4.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 7.00000000e+00] reward= 0.19999999999999998 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {'1f1319cd-9f41-4509-8ce6-56371750c4fd': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'fb206851-8d39-435c-a61d-4ba69d530516': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '4102c4d0-1943-419c-ac6b-a334d55523c8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 1\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'095d3715-ec2b-4e6c-9958-052b14d84fa2': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'fb206851-8d39-435c-a61d-4ba69d530516': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '4102c4d0-1943-419c-ac6b-a334d55523c8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '1f1319cd-9f41-4509-8ce6-56371750c4fd': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 4.60000000e+01 6.95780000e+04 1.51256522e+03\n",
      " 1.38000000e+00 4.60000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 3.00000000e+00 8.00000000e+00 8.00000000e+00] reward= -9.8 done= True\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {'095d3715-ec2b-4e6c-9958-052b14d84fa2': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'fb206851-8d39-435c-a61d-4ba69d530516': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '4102c4d0-1943-419c-ac6b-a334d55523c8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '1f1319cd-9f41-4509-8ce6-56371750c4fd': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.0645000e+00 7.7000000e+01 2.3803000e+04 3.0912987e+02 2.3100000e+00\n",
      " 7.7000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 9.0000000e+00 1.0000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.0645000e+00 7.7000000e+01 2.3803000e+04 3.0912987e+02 2.3100000e+00\n",
      " 7.7000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 9.0000000e+00 2.0000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.0645000e+00 7.7000000e+01 2.3803000e+04 3.0912987e+02 2.3100000e+00\n",
      " 7.7000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 8.0000000e+00 3.0000000e+00] reward= 1.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.0645000e+00 7.7000000e+01 2.3803000e+04 3.0912987e+02 2.3100000e+00\n",
      " 7.7000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 8.0000000e+00 4.0000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.0645000e+00 7.7000000e+01 2.3803000e+04 3.0912987e+02 2.3100000e+00\n",
      " 7.7000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 8.0000000e+00 5.0000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.0645000e+00 7.7000000e+01 2.3803000e+04 3.0912987e+02 2.3100000e+00\n",
      " 7.7000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 8.0000000e+00 6.0000000e+00] reward= 1.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645000e+00 7.7000000e+01 2.3803000e+04 3.0912987e+02 2.3100000e+00\n",
      " 7.7000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 8.0000000e+00 7.0000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'e05d0165-917b-4bf7-a81b-15a110c73736': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645000e+00 7.7000000e+01 2.3803000e+04 3.0912987e+02 2.3100000e+00\n",
      " 7.7000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 8.0000000e+00 8.0000000e+00] reward= 0.9 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {}, 'sell_open_uuids': {'e05d0165-917b-4bf7-a81b-15a110c73736': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 9.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.4\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'e05d0165-917b-4bf7-a81b-15a110c73736': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645000e+00 7.7000000e+01 2.3803000e+04 3.0912987e+02 2.3100000e+00\n",
      " 7.7000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 2.0000000e+00\n",
      " 7.0000000e+00 9.0000000e+00] reward= -0.30000000000000004 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 9.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.4, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'e05d0165-917b-4bf7-a81b-15a110c73736': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 10.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'e05d0165-917b-4bf7-a81b-15a110c73736': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645000e+00 7.7000000e+01 2.3803000e+04 3.0912987e+02 2.3100000e+00\n",
      " 7.7000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 2.0000000e+00\n",
      " 7.0000000e+00 1.0000000e+01] reward= -0.6 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 10.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'e05d0165-917b-4bf7-a81b-15a110c73736': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 11.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'f277e083-ffa5-42ab-bcff-509745c430b8': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'e05d0165-917b-4bf7-a81b-15a110c73736': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645000e+00 7.7000000e+01 2.3803000e+04 3.0912987e+02 2.3100000e+00\n",
      " 7.7000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 2.0000000e+00\n",
      " 7.0000000e+00 1.1000000e+01] reward= 0.7999999999999999 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 11.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {'f277e083-ffa5-42ab-bcff-509745c430b8': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'e05d0165-917b-4bf7-a81b-15a110c73736': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 12.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'e05d0165-917b-4bf7-a81b-15a110c73736': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'f277e083-ffa5-42ab-bcff-509745c430b8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645000e+00 7.7000000e+01 2.3803000e+04 3.0912987e+02 2.3100000e+00\n",
      " 7.7000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 3.0000000e+00\n",
      " 6.0000000e+00 1.2000000e+01] reward= -9.8 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 12.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'bc78f1c6-45c3-4629-a3da-78cdd6d1c97d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'e05d0165-917b-4bf7-a81b-15a110c73736': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'f277e083-ffa5-42ab-bcff-509745c430b8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 2.70000000e+01 3.42700000e+03 1.26925926e+02\n",
      " 8.10000000e-01 2.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 2.70000000e+01 3.42700000e+03 1.26925926e+02\n",
      " 8.10000000e-01 2.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 2.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 2.70000000e+01 3.42700000e+03 1.26925926e+02\n",
      " 8.10000000e-01 2.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.00000000e+00 3.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 2.70000000e+01 3.42700000e+03 1.26925926e+02\n",
      " 8.10000000e-01 2.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.00000000e+00 4.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'41633a62-7332-4a97-b58c-5ba19a25fbb4': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 2.70000000e+01 3.42700000e+03 1.26925926e+02\n",
      " 8.10000000e-01 2.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.00000000e+00 5.00000000e+00] reward= 0.9 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {}, 'sell_open_uuids': {'41633a62-7332-4a97-b58c-5ba19a25fbb4': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.4\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '41633a62-7332-4a97-b58c-5ba19a25fbb4': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 2.70000000e+01 3.42700000e+03 1.26925926e+02\n",
      " 8.10000000e-01 2.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 6.00000000e+00] reward= -0.30000000000000004 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.4, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '41633a62-7332-4a97-b58c-5ba19a25fbb4': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'9ddeb1f6-338f-48f3-86a2-607bec9dc36d': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '41633a62-7332-4a97-b58c-5ba19a25fbb4': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 2.70000000e+01 3.42700000e+03 1.26925926e+02\n",
      " 8.10000000e-01 2.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 7.00000000e+00] reward= 0.19999999999999998 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {'9ddeb1f6-338f-48f3-86a2-607bec9dc36d': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '41633a62-7332-4a97-b58c-5ba19a25fbb4': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 1\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'25e2dbdf-4d0a-4d05-aa9f-3166052cbd64': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '41633a62-7332-4a97-b58c-5ba19a25fbb4': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '9ddeb1f6-338f-48f3-86a2-607bec9dc36d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 2.70000000e+01 3.42700000e+03 1.26925926e+02\n",
      " 8.10000000e-01 2.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 3.00000000e+00 8.00000000e+00 8.00000000e+00] reward= -9.8 done= True\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {'25e2dbdf-4d0a-4d05-aa9f-3166052cbd64': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'0b0f91c5-8f75-489c-a1c7-8094bcfef476': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '41633a62-7332-4a97-b58c-5ba19a25fbb4': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '9ddeb1f6-338f-48f3-86a2-607bec9dc36d': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -0.2\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 3.70000000e+01 7.28960000e+04 1.97016216e+03\n",
      " 1.11000000e+00 3.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+01 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -0.2, 'buy_open_uuids': {}, 'sell_open_uuids': {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.70000000e+01 7.28960000e+04 1.97016216e+03\n",
      " 1.11000000e+00 3.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 1.00000000e+01 2.00000000e+00] reward= -0.8 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'61a26dcf-26ff-4083-b8fa-08ae2b4904b8': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.70000000e+01 7.28960000e+04 1.97016216e+03\n",
      " 1.11000000e+00 3.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 1.00000000e+01 3.00000000e+00] reward= 0.9 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {'61a26dcf-26ff-4083-b8fa-08ae2b4904b8': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.4\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '61a26dcf-26ff-4083-b8fa-08ae2b4904b8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.70000000e+01 7.28960000e+04 1.97016216e+03\n",
      " 1.11000000e+00 3.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 9.00000000e+00 4.00000000e+00] reward= -0.30000000000000004 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.4, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '61a26dcf-26ff-4083-b8fa-08ae2b4904b8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '61a26dcf-26ff-4083-b8fa-08ae2b4904b8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.70000000e+01 7.28960000e+04 1.97016216e+03\n",
      " 1.11000000e+00 3.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 5.00000000e+00] reward= -0.6 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '61a26dcf-26ff-4083-b8fa-08ae2b4904b8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '61a26dcf-26ff-4083-b8fa-08ae2b4904b8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.70000000e+01 7.28960000e+04 1.97016216e+03\n",
      " 1.11000000e+00 3.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 6.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '61a26dcf-26ff-4083-b8fa-08ae2b4904b8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'7972d579-fadf-4d98-89d9-93f931aeb8ad': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '61a26dcf-26ff-4083-b8fa-08ae2b4904b8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.70000000e+01 7.28960000e+04 1.97016216e+03\n",
      " 1.11000000e+00 3.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 7.00000000e+00] reward= 0.7999999999999999 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {'7972d579-fadf-4d98-89d9-93f931aeb8ad': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '61a26dcf-26ff-4083-b8fa-08ae2b4904b8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '61a26dcf-26ff-4083-b8fa-08ae2b4904b8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7972d579-fadf-4d98-89d9-93f931aeb8ad': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.70000000e+01 7.28960000e+04 1.97016216e+03\n",
      " 1.11000000e+00 3.70000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 3.00000000e+00 8.00000000e+00 8.00000000e+00] reward= -9.8 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'538f3db3-dad5-499a-86d4-5c2cae11b3c9': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '61a26dcf-26ff-4083-b8fa-08ae2b4904b8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '7972d579-fadf-4d98-89d9-93f931aeb8ad': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450e+00 5.00000e+01 5.79840e+04 1.15968e+03 1.50000e+00 5.00000e+00\n",
      " 1.00000e+02 0.00000e+00 0.00000e+00 0.00000e+00 9.00000e+00 1.00000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450e+00 5.00000e+01 5.79840e+04 1.15968e+03 1.50000e+00 5.00000e+00\n",
      " 1.00000e+02 0.00000e+00 0.00000e+00 0.00000e+00 8.00000e+00 2.00000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450e+00 5.00000e+01 5.79840e+04 1.15968e+03 1.50000e+00 5.00000e+00\n",
      " 1.00000e+02 0.00000e+00 0.00000e+00 0.00000e+00 7.00000e+00 3.00000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450e+00 5.00000e+01 5.79840e+04 1.15968e+03 1.50000e+00 5.00000e+00\n",
      " 1.00000e+02 0.00000e+00 0.00000e+00 0.00000e+00 6.00000e+00 4.00000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450e+00 5.00000e+01 5.79840e+04 1.15968e+03 1.50000e+00 5.00000e+00\n",
      " 1.00000e+02 0.00000e+00 0.00000e+00 0.00000e+00 5.00000e+00 5.00000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450e+00 5.00000e+01 5.79840e+04 1.15968e+03 1.50000e+00 5.00000e+00\n",
      " 1.00000e+02 0.00000e+00 0.00000e+00 0.00000e+00 5.00000e+00 6.00000e+00] reward= 1.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450e+00 5.00000e+01 5.79840e+04 1.15968e+03 1.50000e+00 5.00000e+00\n",
      " 1.00000e+02 0.00000e+00 0.00000e+00 1.00000e+00 4.00000e+00 7.00000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450e+00 5.00000e+01 5.79840e+04 1.15968e+03 1.50000e+00 5.00000e+00\n",
      " 1.00000e+02 0.00000e+00 0.00000e+00 1.00000e+00 3.00000e+00 8.00000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 9.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450e+00 5.00000e+01 5.79840e+04 1.15968e+03 1.50000e+00 5.00000e+00\n",
      " 1.00000e+02 0.00000e+00 0.00000e+00 1.00000e+00 3.00000e+00 9.00000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 9.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 10.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450e+00 5.00000e+01 5.79840e+04 1.15968e+03 1.50000e+00 5.00000e+00\n",
      " 1.00000e+02 0.00000e+00 0.00000e+00 1.00000e+00 2.00000e+00 1.00000e+01] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 10.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 11.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450e+00 5.00000e+01 5.79840e+04 1.15968e+03 1.50000e+00 5.00000e+00\n",
      " 1.00000e+02 0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 1.10000e+01] reward= 0.9 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 11.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 12.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450e+00 5.00000e+01 5.79840e+04 1.15968e+03 1.50000e+00 5.00000e+00\n",
      " 1.00000e+02 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.20000e+01] reward= -9.9 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 12.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'2deb2c66-4b72-4175-b537-db9134c32407': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -0.2\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 3.40000000e+01 7.36870000e+04 2.16726471e+03\n",
      " 1.02000000e+00 3.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+01 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -0.2, 'buy_open_uuids': {}, 'sell_open_uuids': {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.30000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.40000000e+01 7.36870000e+04 2.16726471e+03\n",
      " 1.02000000e+00 3.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.00000000e+00 2.00000000e+00] reward= -0.10000000000000003 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.30000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.40000000e+01 7.36870000e+04 2.16726471e+03\n",
      " 1.02000000e+00 3.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.00000000e+00 3.00000000e+00] reward= 0.20000000000000004 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.40000000e+01 7.36870000e+04 2.16726471e+03\n",
      " 1.02000000e+00 3.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 4.00000000e+00] reward= -0.9 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.40000000e+01 7.36870000e+04 2.16726471e+03\n",
      " 1.02000000e+00 3.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 7.00000000e+00 5.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.40000000e+01 7.36870000e+04 2.16726471e+03\n",
      " 1.02000000e+00 3.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 6.00000000e+00 6.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.40000000e+01 7.36870000e+04 2.16726471e+03\n",
      " 1.02000000e+00 3.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 5.00000000e+00 7.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.40000000e+01 7.36870000e+04 2.16726471e+03\n",
      " 1.02000000e+00 3.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 4.00000000e+00 8.00000000e+00] reward= 0.7999999999999999 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 9.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.4\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'38ff0749-6f08-47fb-b2d3-28727a0650a2': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.40000000e+01 7.36870000e+04 2.16726471e+03\n",
      " 1.02000000e+00 3.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 4.00000000e+00 9.00000000e+00] reward= -0.19999999999999998 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 9.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.4, 'buy_open_uuids': {}, 'sell_open_uuids': {'38ff0749-6f08-47fb-b2d3-28727a0650a2': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 10.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '38ff0749-6f08-47fb-b2d3-28727a0650a2': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 3.40000000e+01 7.36870000e+04 2.16726471e+03\n",
      " 1.02000000e+00 3.40000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 3.00000000e+00 3.00000000e+00 1.00000000e+01] reward= -9.6 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 10.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1be7702a-ab3c-4282-8b16-3d58e643da54': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'ef7fed8a-5035-4a44-96f7-810e9e39d9fb': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '38ff0749-6f08-47fb-b2d3-28727a0650a2': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -0.2\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.0645e+00 6.4000e+01 2.5120e+03 3.9250e+01 1.9200e+00 6.4000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+01 1.0000e+00] reward= 0.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -0.2, 'buy_open_uuids': {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 6.4000e+01 2.5120e+03 3.9250e+01 1.9200e+00 6.4000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 1.0000e+00 1.0000e+01 2.0000e+00] reward= -0.8 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 6.4000e+01 2.5120e+03 3.9250e+01 1.9200e+00 6.4000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 1.0000e+00 9.0000e+00 3.0000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.1\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 6.4000e+01 2.5120e+03 3.9250e+01 1.9200e+00 6.4000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 1.0000e+00 8.0000e+00 4.0000e+00] reward= 0.9 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.1, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.30000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'78c282cf-0e6e-45ca-bca6-bb97e8c9a111': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 6.4000e+01 2.5120e+03 3.9250e+01 1.9200e+00 6.4000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 1.0000e+00 8.0000e+00 5.0000e+00] reward= -0.20000000000000004 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.30000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {'78c282cf-0e6e-45ca-bca6-bb97e8c9a111': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.4\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '78c282cf-0e6e-45ca-bca6-bb97e8c9a111': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 6.4000e+01 2.5120e+03 3.9250e+01 1.9200e+00 6.4000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 2.0000e+00 7.0000e+00 6.0000e+00] reward= -0.09999999999999998 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.4, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '78c282cf-0e6e-45ca-bca6-bb97e8c9a111': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '78c282cf-0e6e-45ca-bca6-bb97e8c9a111': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 6.4000e+01 2.5120e+03 3.9250e+01 1.9200e+00 6.4000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 2.0000e+00 6.0000e+00 7.0000e+00] reward= -0.6 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '78c282cf-0e6e-45ca-bca6-bb97e8c9a111': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '78c282cf-0e6e-45ca-bca6-bb97e8c9a111': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 6.4000e+01 2.5120e+03 3.9250e+01 1.9200e+00 6.4000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 2.0000e+00 5.0000e+00 8.0000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '78c282cf-0e6e-45ca-bca6-bb97e8c9a111': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 9.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'9224d7ee-13b6-4678-a603-9933c15eb659': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '78c282cf-0e6e-45ca-bca6-bb97e8c9a111': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 6.4000e+01 2.5120e+03 3.9250e+01 1.9200e+00 6.4000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 2.0000e+00 5.0000e+00 9.0000e+00] reward= 0.7999999999999999 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 9.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {'9224d7ee-13b6-4678-a603-9933c15eb659': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '78c282cf-0e6e-45ca-bca6-bb97e8c9a111': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 10.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '78c282cf-0e6e-45ca-bca6-bb97e8c9a111': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '9224d7ee-13b6-4678-a603-9933c15eb659': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 6.4000e+01 2.5120e+03 3.9250e+01 1.9200e+00 6.4000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 3.0000e+00 4.0000e+00 1.0000e+01] reward= -9.8 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 10.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'854e3386-740e-46b0-84fb-228de8934350': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '78c282cf-0e6e-45ca-bca6-bb97e8c9a111': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '9224d7ee-13b6-4678-a603-9933c15eb659': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 6.00000000e+01 3.69340000e+04 6.15566667e+02\n",
      " 1.80000000e+00 6.00000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'f7330447-ad52-4394-8d6c-3c8ca0486be5': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 6.00000000e+01 3.69340000e+04 6.15566667e+02\n",
      " 1.80000000e+00 6.00000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 2.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {'f7330447-ad52-4394-8d6c-3c8ca0486be5': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.30000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'04f210d7-f1a3-4eed-b1ef-922a9d5efc1e': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'f7330447-ad52-4394-8d6c-3c8ca0486be5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.00000000e+01 3.69340000e+04 6.15566667e+02\n",
      " 1.80000000e+00 6.00000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.00000000e+00 3.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.30000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {'04f210d7-f1a3-4eed-b1ef-922a9d5efc1e': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'f7330447-ad52-4394-8d6c-3c8ca0486be5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.4\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'a626c401-deab-4a07-9319-38573711bf8c': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'f7330447-ad52-4394-8d6c-3c8ca0486be5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '04f210d7-f1a3-4eed-b1ef-922a9d5efc1e': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.00000000e+01 3.69340000e+04 6.15566667e+02\n",
      " 1.80000000e+00 6.00000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 9.00000000e+00 4.00000000e+00] reward= -0.09999999999999998 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.4, 'buy_open_uuids': {'a626c401-deab-4a07-9319-38573711bf8c': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'f7330447-ad52-4394-8d6c-3c8ca0486be5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '04f210d7-f1a3-4eed-b1ef-922a9d5efc1e': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'f7330447-ad52-4394-8d6c-3c8ca0486be5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '04f210d7-f1a3-4eed-b1ef-922a9d5efc1e': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'a626c401-deab-4a07-9319-38573711bf8c': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.00000000e+01 3.69340000e+04 6.15566667e+02\n",
      " 1.80000000e+00 6.00000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 3.00000000e+00 8.00000000e+00 5.00000000e+00] reward= -9.6 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'f7330447-ad52-4394-8d6c-3c8ca0486be5': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '04f210d7-f1a3-4eed-b1ef-922a9d5efc1e': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'a626c401-deab-4a07-9319-38573711bf8c': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.0645000e+00 6.3000000e+01 5.6594000e+04 8.9831746e+02 1.8900000e+00\n",
      " 6.3000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+01 1.0000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'7d2dbdea-6877-4823-b725-37e41acb6133': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.0645000e+00 6.3000000e+01 5.6594000e+04 8.9831746e+02 1.8900000e+00\n",
      " 6.3000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+01 2.0000000e+00] reward= 1.0 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {}, 'sell_open_uuids': {'7d2dbdea-6877-4823-b725-37e41acb6133': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.30000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'aa435293-63e3-41c4-8080-89738d35afa4': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'7d2dbdea-6877-4823-b725-37e41acb6133': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645000e+00 6.3000000e+01 5.6594000e+04 8.9831746e+02 1.8900000e+00\n",
      " 6.3000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+01 3.0000000e+00] reward= 0.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.30000000000000004, 'buy_open_uuids': {'aa435293-63e3-41c4-8080-89738d35afa4': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'7d2dbdea-6877-4823-b725-37e41acb6133': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.4\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'48d1dd66-7b70-450a-a574-9a134003c972': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'7d2dbdea-6877-4823-b725-37e41acb6133': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'aa435293-63e3-41c4-8080-89738d35afa4': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645000e+00 6.3000000e+01 5.6594000e+04 8.9831746e+02 1.8900000e+00\n",
      " 6.3000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 2.0000000e+00\n",
      " 1.0000000e+01 4.0000000e+00] reward= -0.09999999999999998 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.4, 'buy_open_uuids': {'48d1dd66-7b70-450a-a574-9a134003c972': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'7d2dbdea-6877-4823-b725-37e41acb6133': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'aa435293-63e3-41c4-8080-89738d35afa4': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 1\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'cab050df-e5e1-46d4-87c5-f2f83ede4b0c': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'7d2dbdea-6877-4823-b725-37e41acb6133': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'aa435293-63e3-41c4-8080-89738d35afa4': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '48d1dd66-7b70-450a-a574-9a134003c972': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645000e+00 6.3000000e+01 5.6594000e+04 8.9831746e+02 1.8900000e+00\n",
      " 6.3000000e+00 1.0000000e+02 0.0000000e+00 0.0000000e+00 3.0000000e+00\n",
      " 1.0000000e+01 5.0000000e+00] reward= -9.6 done= True\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {'cab050df-e5e1-46d4-87c5-f2f83ede4b0c': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'7d2dbdea-6877-4823-b725-37e41acb6133': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'aa435293-63e3-41c4-8080-89738d35afa4': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '48d1dd66-7b70-450a-a574-9a134003c972': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 6.30000000e+01 4.94640000e+04 7.85142857e+02\n",
      " 1.89000000e+00 6.30000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+01 1.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 6.30000000e+01 4.94640000e+04 7.85142857e+02\n",
      " 1.89000000e+00 6.30000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 2.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 6.30000000e+01 4.94640000e+04 7.85142857e+02\n",
      " 1.89000000e+00 6.30000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 3.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: 0.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.06450000e+00 6.30000000e+01 4.94640000e+04 7.85142857e+02\n",
      " 1.89000000e+00 6.30000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.00000000e+00 4.00000000e+00] reward= 1.0 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': 0.0, 'buy_open_uuids': {}, 'sell_open_uuids': {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.30000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'19658e7e-e0b2-4f06-9689-a15356adfcda': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.30000000e+01 4.94640000e+04 7.85142857e+02\n",
      " 1.89000000e+00 6.30000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.00000000e+00 5.00000000e+00] reward= 0.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.30000000000000004, 'buy_open_uuids': {'19658e7e-e0b2-4f06-9689-a15356adfcda': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '19658e7e-e0b2-4f06-9689-a15356adfcda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.30000000e+01 4.94640000e+04 7.85142857e+02\n",
      " 1.89000000e+00 6.30000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 8.00000000e+00 6.00000000e+00] reward= -0.7 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '19658e7e-e0b2-4f06-9689-a15356adfcda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 7.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '19658e7e-e0b2-4f06-9689-a15356adfcda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.30000000e+01 4.94640000e+04 7.85142857e+02\n",
      " 1.89000000e+00 6.30000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 7.00000000e+00 7.00000000e+00] reward= 0.7999999999999999 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 7.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '19658e7e-e0b2-4f06-9689-a15356adfcda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 8.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '19658e7e-e0b2-4f06-9689-a15356adfcda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.30000000e+01 4.94640000e+04 7.85142857e+02\n",
      " 1.89000000e+00 6.30000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 6.00000000e+00 8.00000000e+00] reward= -0.7999999999999999 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 8.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '19658e7e-e0b2-4f06-9689-a15356adfcda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 9.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'860158e8-723b-48c3-b64a-84bc84d5dee8': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '19658e7e-e0b2-4f06-9689-a15356adfcda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.30000000e+01 4.94640000e+04 7.85142857e+02\n",
      " 1.89000000e+00 6.30000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 2.00000000e+00 6.00000000e+00 9.00000000e+00] reward= 0.7999999999999999 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 9.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {'860158e8-723b-48c3-b64a-84bc84d5dee8': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '19658e7e-e0b2-4f06-9689-a15356adfcda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 10.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 1\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'a7f789be-15b8-470a-8f2a-07921f0d7ab0': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '19658e7e-e0b2-4f06-9689-a15356adfcda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '860158e8-723b-48c3-b64a-84bc84d5dee8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.06450000e+00 6.30000000e+01 4.94640000e+04 7.85142857e+02\n",
      " 1.89000000e+00 6.30000000e+00 1.00000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 3.00000000e+00 6.00000000e+00 1.00000000e+01] reward= -9.8 done= True\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 10.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {'a7f789be-15b8-470a-8f2a-07921f0d7ab0': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {'7e7f2183-99af-463e-ab5e-91d99c3abf90': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '19658e7e-e0b2-4f06-9689-a15356adfcda': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '860158e8-723b-48c3-b64a-84bc84d5dee8': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 1.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 0\n",
      "Previous Reward: -0.2\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {'1cf60805-46d4-413a-a6f9-858af32119db': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {}\n",
      "obs= [1.0645e+00 5.7000e+01 9.9693e+04 1.7490e+03 1.7100e+00 5.7000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+01 1.0000e+00] reward= 0.0 done= False\n",
      "{'action': 0, 'current_price': 1.0645, 'current_step': 1.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 0, 'previous_reward': -0.2, 'buy_open_uuids': {'1cf60805-46d4-413a-a6f9-858af32119db': {'open_price': 1.0645, 'available_time': 100}}, 'sell_open_uuids': {}, 'previous_trade_details': {}}\n",
      "\n",
      "Step: 2.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 1\n",
      "Previous Reward: -0.30000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'b423136e-11de-4445-b672-575a3aa6fc75': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'1cf60805-46d4-413a-a6f9-858af32119db': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 5.7000e+01 9.9693e+04 1.7490e+03 1.7100e+00 5.7000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 1.0000e+00 1.0000e+01 2.0000e+00] reward= -0.10000000000000003 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 2.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 1, 'previous_reward': -0.30000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {'b423136e-11de-4445-b672-575a3aa6fc75': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'1cf60805-46d4-413a-a6f9-858af32119db': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 3.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -1.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1cf60805-46d4-413a-a6f9-858af32119db': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'b423136e-11de-4445-b672-575a3aa6fc75': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 5.7000e+01 9.9693e+04 1.7490e+03 1.7100e+00 5.7000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 2.0000e+00 9.0000e+00 3.0000e+00] reward= -0.7 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 3.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -1.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1cf60805-46d4-413a-a6f9-858af32119db': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'b423136e-11de-4445-b672-575a3aa6fc75': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 4.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.20000000000000004\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1cf60805-46d4-413a-a6f9-858af32119db': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'b423136e-11de-4445-b672-575a3aa6fc75': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 5.7000e+01 9.9693e+04 1.7490e+03 1.7100e+00 5.7000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 2.0000e+00 8.0000e+00 4.0000e+00] reward= 0.7999999999999999 done= False\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 4.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.20000000000000004, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1cf60805-46d4-413a-a6f9-858af32119db': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'b423136e-11de-4445-b672-575a3aa6fc75': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 5.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 2\n",
      "Previous Reward: -0.4\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {'4f963634-e0d5-447c-8226-171290455408': {'open_price': 1.0645, 'available_time': 100}}\n",
      "Previous Trade Details: {'1cf60805-46d4-413a-a6f9-858af32119db': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'b423136e-11de-4445-b672-575a3aa6fc75': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 5.7000e+01 9.9693e+04 1.7490e+03 1.7100e+00 5.7000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 2.0000e+00 8.0000e+00 5.0000e+00] reward= -0.19999999999999998 done= False\n",
      "{'action': 1, 'current_price': 1.0645, 'current_step': 5.0, 'current_profit_loss': 0.0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 2, 'previous_reward': -0.4, 'buy_open_uuids': {}, 'sell_open_uuids': {'4f963634-e0d5-447c-8226-171290455408': {'open_price': 1.0645, 'available_time': 100}}, 'previous_trade_details': {'1cf60805-46d4-413a-a6f9-858af32119db': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'b423136e-11de-4445-b672-575a3aa6fc75': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n",
      "Step: 6.0\n",
      "Price: 1.0645\n",
      "Profit/Loss: 0.0\n",
      "Net Gains: 0.0\n",
      "Current Buy Open Trades: 0\n",
      "Current Sell Open Trades: 0\n",
      "Auto Terminated Trades: 3\n",
      "Previous Reward: -10.0\n",
      "Action Space: Discrete(6)\n",
      "Observation Space: Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float32)\n",
      "Buy Open Trades: {}\n",
      "Sell Open Trades: {}\n",
      "Previous Trade Details: {'1cf60805-46d4-413a-a6f9-858af32119db': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'b423136e-11de-4445-b672-575a3aa6fc75': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '4f963634-e0d5-447c-8226-171290455408': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}\n",
      "obs= [1.0645e+00 5.7000e+01 9.9693e+04 1.7490e+03 1.7100e+00 5.7000e+00\n",
      " 1.0000e+02 0.0000e+00 0.0000e+00 3.0000e+00 7.0000e+00 6.0000e+00] reward= -9.6 done= True\n",
      "{'action': 5, 'current_price': 1.0645, 'current_step': 6.0, 'current_profit_loss': 0, 'total_profit_loss': 0.0, 'net_gains': 0.0, 'current_buy_open_trades': 0, 'current_sell_open_trades': 0, 'auto_terminated_trades': 3, 'previous_reward': -10.0, 'buy_open_uuids': {}, 'sell_open_uuids': {}, 'previous_trade_details': {'1cf60805-46d4-413a-a6f9-858af32119db': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, 'b423136e-11de-4445-b672-575a3aa6fc75': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}, '4f963634-e0d5-447c-8226-171290455408': {'open_price': 1.0645, 'available_time': 100, 'close_price': 1.0645}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = TradingEnv(data)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "for i in range(20):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        print(\"obs=\", obs, \"reward=\", reward, \"done=\", done)\n",
    "        print(info)\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Logging to ./logs/PPO_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rifat\\miniconda3\\envs\\tf\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:140: UserWarning: You have specified a mini-batch size of 4096, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2048`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 2048\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=2048 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10.1     |\n",
      "|    ep_rew_mean     | -8.94    |\n",
      "| time/              |          |\n",
      "|    fps             | 274      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.1        |\n",
      "|    ep_rew_mean          | -8.54       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016782308 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.000939    |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 3.21        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.3        |\n",
      "|    ep_rew_mean          | -7.85       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017026288 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | -0.000665   |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 0.994       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 3.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.7        |\n",
      "|    ep_rew_mean          | -7.88       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012307932 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -0.000217   |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 1.62        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.7        |\n",
      "|    ep_rew_mean          | -7.21       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034805514 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    value_loss           | 3.28        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 12.8         |\n",
      "|    ep_rew_mean          | -7.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 332          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044569736 |\n",
      "|    clip_fraction        | 0.059        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 2.17         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | 0.00127      |\n",
      "|    value_loss           | 4.4          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.1        |\n",
      "|    ep_rew_mean          | -6.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 337         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010062747 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 2.4         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    value_loss           | 4.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.4        |\n",
      "|    ep_rew_mean          | -6.93       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 338         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008373549 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 3.84        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 0.00107     |\n",
      "|    value_loss           | 7.84        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.3        |\n",
      "|    ep_rew_mean          | -7          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 338         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012582876 |\n",
      "|    clip_fraction        | 0.0663      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 2.87        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    value_loss           | 5.92        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.4        |\n",
      "|    ep_rew_mean          | -6.18       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 336         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010307533 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 3.28        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    value_loss           | 6.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.7        |\n",
      "|    ep_rew_mean          | -5.58       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014064621 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 4.49        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    value_loss           | 9           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.5        |\n",
      "|    ep_rew_mean          | -4.97       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010385212 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 4.04        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    value_loss           | 8.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.9        |\n",
      "|    ep_rew_mean          | -4.92       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 337         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009176912 |\n",
      "|    clip_fraction        | 0.00229     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 4.95        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -6.51e-05   |\n",
      "|    value_loss           | 9.95        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.2        |\n",
      "|    ep_rew_mean          | -4.48       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004937661 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 5.89        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.9        |\n",
      "|    ep_rew_mean          | -4.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006953009 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 5.7         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.3         |\n",
      "|    ep_rew_mean          | -4.32        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 342          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055550425 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 6.14         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    value_loss           | 12.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.5        |\n",
      "|    ep_rew_mean          | -4.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006171046 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.000148   |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.5        |\n",
      "|    ep_rew_mean          | -3.66       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 342         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006048467 |\n",
      "|    clip_fraction        | 0.0881      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 5.89        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 14.9       |\n",
      "|    ep_rew_mean          | -3.51      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 343        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 113        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00820866 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 2.64e-05   |\n",
      "|    learning_rate        | 0.0025     |\n",
      "|    loss                 | 5.76       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.00092   |\n",
      "|    value_loss           | 11.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 15.4         |\n",
      "|    ep_rew_mean          | -4.12        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 343          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048670135 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 5.85         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000439    |\n",
      "|    value_loss           | 11.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 15.8         |\n",
      "|    ep_rew_mean          | -2.81        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 345          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075639444 |\n",
      "|    clip_fraction        | 0.0586       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 5.31         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.000314    |\n",
      "|    value_loss           | 10.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.3         |\n",
      "|    ep_rew_mean          | -3.74        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 347          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037931157 |\n",
      "|    clip_fraction        | 0.00728      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 7.25e-05     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 5.9          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | 0.0012       |\n",
      "|    value_loss           | 11.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.4         |\n",
      "|    ep_rew_mean          | -3.37        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 350          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 134          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015916023 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 6.27         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | 0.000557     |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.2        |\n",
      "|    ep_rew_mean          | -3.95       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 350         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006758789 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -4.53e-05   |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 6.1         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.7         |\n",
      "|    ep_rew_mean          | -4.28        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 353          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039274367 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 5.55         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    value_loss           | 11.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18.7         |\n",
      "|    ep_rew_mean          | -2.35        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 355          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059390715 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 4.83         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    value_loss           | 9.68         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17          |\n",
      "|    ep_rew_mean          | -4.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 356         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011839474 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 5.67        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.7         |\n",
      "|    ep_rew_mean          | -4.12        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 357          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 160          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009845751 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 5.37         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.000434    |\n",
      "|    value_loss           | 10.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | -3.59       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021678768 |\n",
      "|    clip_fraction        | 0.431       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.979      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 5.15        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.000638    |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 19.8          |\n",
      "|    ep_rew_mean          | -2.67         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 358           |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 171           |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038692766 |\n",
      "|    clip_fraction        | 0.088         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.968        |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 4.7           |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | 0.00104       |\n",
      "|    value_loss           | 9.42          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.1        |\n",
      "|    ep_rew_mean          | -3.38       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009311562 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.943      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 5.34        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.3        |\n",
      "|    ep_rew_mean          | -2.96       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010462549 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.928      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 4.42        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.00311     |\n",
      "|    value_loss           | 8.97        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.5         |\n",
      "|    ep_rew_mean          | -3.18        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 187          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036756764 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.882       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 4.91         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000853    |\n",
      "|    value_loss           | 9.85         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.3        |\n",
      "|    ep_rew_mean          | -1.91       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017916545 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.856      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 4.82        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    value_loss           | 9.65        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.3         |\n",
      "|    ep_rew_mean          | -2.01        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015090194 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.799       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 4.52         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00024     |\n",
      "|    value_loss           | 9.33         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -2.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013161873 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.726      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 4.47        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    value_loss           | 8.91        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.6        |\n",
      "|    ep_rew_mean          | -1.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 364         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010008523 |\n",
      "|    clip_fraction        | 0.0346      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.677      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 4.04        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.000917   |\n",
      "|    value_loss           | 8.09        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 42.4       |\n",
      "|    ep_rew_mean          | -1.41      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 365        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 212        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00064832 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.627     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0025     |\n",
      "|    loss                 | 3.46       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -2.22e-05  |\n",
      "|    value_loss           | 6.97       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45          |\n",
      "|    ep_rew_mean          | -1.43       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008461205 |\n",
      "|    clip_fraction        | 0.0264      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.594      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 3.9         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00116    |\n",
      "|    value_loss           | 7.8         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 51.8         |\n",
      "|    ep_rew_mean          | -1.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 368          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 222          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075936737 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 3.39         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.001       |\n",
      "|    value_loss           | 6.79         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 58.9         |\n",
      "|    ep_rew_mean          | -1.55        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 370          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007023759 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 2.99         |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -7.19e-05    |\n",
      "|    value_loss           | 5.99         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.6         |\n",
      "|    ep_rew_mean          | -1.66        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 372          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.935892e-05 |\n",
      "|    clip_fraction        | 0.0588       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.384       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 2.78         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    value_loss           | 5.58         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 69.5         |\n",
      "|    ep_rew_mean          | -1.34        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 373          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 235          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011194723 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 3            |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    value_loss           | 6            |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 75.4         |\n",
      "|    ep_rew_mean          | -1.69        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 240          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014700013 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.371       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 2.74         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    value_loss           | 5.49         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 82.7         |\n",
      "|    ep_rew_mean          | -1.41        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 376          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 244          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011383523 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.34        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 2.58         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.000954    |\n",
      "|    value_loss           | 5.16         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 87.8        |\n",
      "|    ep_rew_mean          | -1.32       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 377         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000368577 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 2.14        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 3.53e-05    |\n",
      "|    value_loss           | 4.31        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.4         |\n",
      "|    ep_rew_mean          | -1.19        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 379          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 253          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010255605 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.348       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 2.93         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000159    |\n",
      "|    value_loss           | 5.86         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 104         |\n",
      "|    ep_rew_mean          | -0.97       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 381         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002305115 |\n",
      "|    clip_fraction        | 0.00791     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 1.77        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.000202   |\n",
      "|    value_loss           | 3.54        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 112           |\n",
      "|    ep_rew_mean          | -0.83         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 382           |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 262           |\n",
      "|    total_timesteps      | 100352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095685455 |\n",
      "|    clip_fraction        | 0.00786       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.291        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 2.13          |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.000271     |\n",
      "|    value_loss           | 4.27          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 116          |\n",
      "|    ep_rew_mean          | -0.962       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 383          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014899259 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.269       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 2.29         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -2.98e-05    |\n",
      "|    value_loss           | 4.58         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 125         |\n",
      "|    ep_rew_mean          | -0.908      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 385         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001200038 |\n",
      "|    clip_fraction        | 9.77e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.26       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 2.08        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.000226   |\n",
      "|    value_loss           | 4.17        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 136           |\n",
      "|    ep_rew_mean          | -0.854        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 386           |\n",
      "|    iterations           | 52            |\n",
      "|    time_elapsed         | 275           |\n",
      "|    total_timesteps      | 106496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021625476 |\n",
      "|    clip_fraction        | 0.0167        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.196        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 1.68          |\n",
      "|    n_updates            | 510           |\n",
      "|    policy_gradient_loss | -0.000472     |\n",
      "|    value_loss           | 3.36          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 148           |\n",
      "|    ep_rew_mean          | -0.658        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 388           |\n",
      "|    iterations           | 53            |\n",
      "|    time_elapsed         | 279           |\n",
      "|    total_timesteps      | 108544        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6510908e-06 |\n",
      "|    clip_fraction        | 0.00928       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.227        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 1.62          |\n",
      "|    n_updates            | 520           |\n",
      "|    policy_gradient_loss | -0.000129     |\n",
      "|    value_loss           | 3.23          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 158           |\n",
      "|    ep_rew_mean          | -0.736        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 389           |\n",
      "|    iterations           | 54            |\n",
      "|    time_elapsed         | 283           |\n",
      "|    total_timesteps      | 110592        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9968272e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.197        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 1.65          |\n",
      "|    n_updates            | 530           |\n",
      "|    policy_gradient_loss | 2.91e-05      |\n",
      "|    value_loss           | 3.3           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 162           |\n",
      "|    ep_rew_mean          | -0.588        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 390           |\n",
      "|    iterations           | 55            |\n",
      "|    time_elapsed         | 288           |\n",
      "|    total_timesteps      | 112640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048090258 |\n",
      "|    clip_fraction        | 0.00581       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.227        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 1.78          |\n",
      "|    n_updates            | 540           |\n",
      "|    policy_gradient_loss | -0.000352     |\n",
      "|    value_loss           | 3.56          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 168          |\n",
      "|    ep_rew_mean          | -0.67        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 392          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 292          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009990605 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 1.67         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | 1.51e-05     |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 176          |\n",
      "|    ep_rew_mean          | -0.802       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 393          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 296          |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012599232 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.167       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 2.02         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.000746    |\n",
      "|    value_loss           | 4.06         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 189          |\n",
      "|    ep_rew_mean          | -0.798       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 394          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 301          |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.829868e-06 |\n",
      "|    clip_fraction        | 0.00444      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.182       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | 5.3e-05      |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 197           |\n",
      "|    ep_rew_mean          | -0.63         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 395           |\n",
      "|    iterations           | 59            |\n",
      "|    time_elapsed         | 305           |\n",
      "|    total_timesteps      | 120832        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030745653 |\n",
      "|    clip_fraction        | 0.0188        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.143        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 1.11          |\n",
      "|    n_updates            | 580           |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    value_loss           | 2.22          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 206           |\n",
      "|    ep_rew_mean          | -0.62         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 396           |\n",
      "|    iterations           | 60            |\n",
      "|    time_elapsed         | 309           |\n",
      "|    total_timesteps      | 122880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020343525 |\n",
      "|    clip_fraction        | 0.0133        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.17         |\n",
      "|    explained_variance   | -2.38e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 1.26          |\n",
      "|    n_updates            | 590           |\n",
      "|    policy_gradient_loss | -0.00105      |\n",
      "|    value_loss           | 2.54          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 216          |\n",
      "|    ep_rew_mean          | -0.72        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 397          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 314          |\n",
      "|    total_timesteps      | 124928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005672816 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.139       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 1.33         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0005      |\n",
      "|    value_loss           | 2.65         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 227          |\n",
      "|    ep_rew_mean          | -0.638       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 399          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 318          |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006365627 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.139       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.985        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.000162    |\n",
      "|    value_loss           | 1.97         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 235           |\n",
      "|    ep_rew_mean          | -0.63         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 400           |\n",
      "|    iterations           | 63            |\n",
      "|    time_elapsed         | 322           |\n",
      "|    total_timesteps      | 129024        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.0469344e-05 |\n",
      "|    clip_fraction        | 0.00732       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.101        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.867         |\n",
      "|    n_updates            | 620           |\n",
      "|    policy_gradient_loss | -1.33e-05     |\n",
      "|    value_loss           | 1.73          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 250          |\n",
      "|    ep_rew_mean          | -0.592       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 401          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 326          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.572827e-05 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.12        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.565        |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.000484    |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 257          |\n",
      "|    ep_rew_mean          | -0.582       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 402          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 330          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.662546e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.115       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 1            |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -2.16e-05    |\n",
      "|    value_loss           | 2            |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 268           |\n",
      "|    ep_rew_mean          | -0.572        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 403           |\n",
      "|    iterations           | 66            |\n",
      "|    time_elapsed         | 334           |\n",
      "|    total_timesteps      | 135168        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024048728 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.129        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.727         |\n",
      "|    n_updates            | 650           |\n",
      "|    policy_gradient_loss | -3.6e-05      |\n",
      "|    value_loss           | 1.45          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 282           |\n",
      "|    ep_rew_mean          | -0.562        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 404           |\n",
      "|    iterations           | 67            |\n",
      "|    time_elapsed         | 339           |\n",
      "|    total_timesteps      | 137216        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022847092 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.133        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 1.06          |\n",
      "|    n_updates            | 660           |\n",
      "|    policy_gradient_loss | -8.88e-05     |\n",
      "|    value_loss           | 2.11          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 295           |\n",
      "|    ep_rew_mean          | -0.542        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 405           |\n",
      "|    iterations           | 68            |\n",
      "|    time_elapsed         | 343           |\n",
      "|    total_timesteps      | 139264        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5428675e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.116        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.74          |\n",
      "|    n_updates            | 670           |\n",
      "|    policy_gradient_loss | 7.88e-05      |\n",
      "|    value_loss           | 1.48          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 307          |\n",
      "|    ep_rew_mean          | -0.564       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 347          |\n",
      "|    total_timesteps      | 141312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002421427 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.112       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.706        |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.000115    |\n",
      "|    value_loss           | 1.41         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 322           |\n",
      "|    ep_rew_mean          | -0.546        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 407           |\n",
      "|    iterations           | 70            |\n",
      "|    time_elapsed         | 351           |\n",
      "|    total_timesteps      | 143360        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024587227 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0928       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.734         |\n",
      "|    n_updates            | 690           |\n",
      "|    policy_gradient_loss | 2.36e-05      |\n",
      "|    value_loss           | 1.47          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 337          |\n",
      "|    ep_rew_mean          | -0.52        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 408          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 356          |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.135014e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.088       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.554        |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -1.9e-06     |\n",
      "|    value_loss           | 1.11         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 345          |\n",
      "|    ep_rew_mean          | -0.52        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 409          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 360          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004793726 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0844      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.698        |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.000223    |\n",
      "|    value_loss           | 1.4          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 366           |\n",
      "|    ep_rew_mean          | -0.692        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 410           |\n",
      "|    iterations           | 73            |\n",
      "|    time_elapsed         | 364           |\n",
      "|    total_timesteps      | 149504        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027360456 |\n",
      "|    clip_fraction        | 0.00107       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.079        |\n",
      "|    explained_variance   | 2.12e-05      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.378         |\n",
      "|    n_updates            | 720           |\n",
      "|    policy_gradient_loss | -0.000167     |\n",
      "|    value_loss           | 0.762         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 382           |\n",
      "|    ep_rew_mean          | -0.654        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 411           |\n",
      "|    iterations           | 74            |\n",
      "|    time_elapsed         | 368           |\n",
      "|    total_timesteps      | 151552        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085645623 |\n",
      "|    clip_fraction        | 0.0132        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0748       |\n",
      "|    explained_variance   | 0.00249       |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.865         |\n",
      "|    n_updates            | 730           |\n",
      "|    policy_gradient_loss | -0.000842     |\n",
      "|    value_loss           | 1.72          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 395           |\n",
      "|    ep_rew_mean          | -0.61         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 411           |\n",
      "|    iterations           | 75            |\n",
      "|    time_elapsed         | 373           |\n",
      "|    total_timesteps      | 153600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5801517e-05 |\n",
      "|    clip_fraction        | 0.0041        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0813       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.546         |\n",
      "|    n_updates            | 740           |\n",
      "|    policy_gradient_loss | 0.000156      |\n",
      "|    value_loss           | 1.09          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 414           |\n",
      "|    ep_rew_mean          | -0.62         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 412           |\n",
      "|    iterations           | 76            |\n",
      "|    time_elapsed         | 377           |\n",
      "|    total_timesteps      | 155648        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010849477 |\n",
      "|    clip_fraction        | 0.00337       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0601       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.351         |\n",
      "|    n_updates            | 750           |\n",
      "|    policy_gradient_loss | -0.000148     |\n",
      "|    value_loss           | 0.703         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 429           |\n",
      "|    ep_rew_mean          | -0.592        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 413           |\n",
      "|    iterations           | 77            |\n",
      "|    time_elapsed         | 381           |\n",
      "|    total_timesteps      | 157696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040149532 |\n",
      "|    clip_fraction        | 0.00586       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0543       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.494         |\n",
      "|    n_updates            | 760           |\n",
      "|    policy_gradient_loss | -0.00083      |\n",
      "|    value_loss           | 0.99          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 443           |\n",
      "|    ep_rew_mean          | -0.574        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 414           |\n",
      "|    iterations           | 78            |\n",
      "|    time_elapsed         | 385           |\n",
      "|    total_timesteps      | 159744        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9227616e-05 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0568       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.187         |\n",
      "|    n_updates            | 770           |\n",
      "|    policy_gradient_loss | 1.83e-05      |\n",
      "|    value_loss           | 0.374         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 461           |\n",
      "|    ep_rew_mean          | -0.51         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 414           |\n",
      "|    iterations           | 79            |\n",
      "|    time_elapsed         | 389           |\n",
      "|    total_timesteps      | 161792        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023746787 |\n",
      "|    clip_fraction        | 0.00225       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0589       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.394         |\n",
      "|    n_updates            | 780           |\n",
      "|    policy_gradient_loss | -0.000228     |\n",
      "|    value_loss           | 0.79          |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 476            |\n",
      "|    ep_rew_mean          | -0.492         |\n",
      "| time/                   |                |\n",
      "|    fps                  | 415            |\n",
      "|    iterations           | 80             |\n",
      "|    time_elapsed         | 394            |\n",
      "|    total_timesteps      | 163840         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000106549356 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.0611        |\n",
      "|    explained_variance   | 5.96e-08       |\n",
      "|    learning_rate        | 0.0025         |\n",
      "|    loss                 | 0.743          |\n",
      "|    n_updates            | 790            |\n",
      "|    policy_gradient_loss | 5.99e-06       |\n",
      "|    value_loss           | 1.49           |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 484          |\n",
      "|    ep_rew_mean          | -0.482       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 416          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 398          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.606447e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0591      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.378        |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -8.76e-06    |\n",
      "|    value_loss           | 0.756        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | -0.482       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 417          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 402          |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001446993 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0681      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.39         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.000226    |\n",
      "|    value_loss           | 0.781        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 518           |\n",
      "|    ep_rew_mean          | -0.366        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 418           |\n",
      "|    iterations           | 83            |\n",
      "|    time_elapsed         | 406           |\n",
      "|    total_timesteps      | 169984        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6476267e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0666       |\n",
      "|    explained_variance   | 0.0143        |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.357         |\n",
      "|    n_updates            | 820           |\n",
      "|    policy_gradient_loss | -0.000111     |\n",
      "|    value_loss           | 0.753         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 529           |\n",
      "|    ep_rew_mean          | -0.356        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 418           |\n",
      "|    iterations           | 84            |\n",
      "|    time_elapsed         | 411           |\n",
      "|    total_timesteps      | 172032        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011501156 |\n",
      "|    clip_fraction        | 0.00137       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0804       |\n",
      "|    explained_variance   | 0.000174      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.567         |\n",
      "|    n_updates            | 830           |\n",
      "|    policy_gradient_loss | 1.92e-05      |\n",
      "|    value_loss           | 1.13          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 545         |\n",
      "|    ep_rew_mean          | -0.292      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 419         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000248867 |\n",
      "|    clip_fraction        | 0.00566     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0698     |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 0.503       |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.000823   |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 560          |\n",
      "|    ep_rew_mean          | -0.462       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 419          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 419          |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.563179e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0673      |\n",
      "|    explained_variance   | 0.0141       |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.559        |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -2.58e-05    |\n",
      "|    value_loss           | 1.11         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 577           |\n",
      "|    ep_rew_mean          | -0.416        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 420           |\n",
      "|    iterations           | 87            |\n",
      "|    time_elapsed         | 423           |\n",
      "|    total_timesteps      | 178176        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0621962e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0627       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.378         |\n",
      "|    n_updates            | 860           |\n",
      "|    policy_gradient_loss | 1.3e-05       |\n",
      "|    value_loss           | 0.756         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 586          |\n",
      "|    ep_rew_mean          | -0.426       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 421          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 427          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.999757e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0649      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.379        |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -2.26e-05    |\n",
      "|    value_loss           | 0.758        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 602           |\n",
      "|    ep_rew_mean          | -0.382        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 422           |\n",
      "|    iterations           | 89            |\n",
      "|    time_elapsed         | 431           |\n",
      "|    total_timesteps      | 182272        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011190094 |\n",
      "|    clip_fraction        | 0.00396       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0782       |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.207         |\n",
      "|    n_updates            | 880           |\n",
      "|    policy_gradient_loss | -0.000592     |\n",
      "|    value_loss           | 0.416         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 622           |\n",
      "|    ep_rew_mean          | -0.364        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 422           |\n",
      "|    iterations           | 90            |\n",
      "|    time_elapsed         | 435           |\n",
      "|    total_timesteps      | 184320        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013862533 |\n",
      "|    clip_fraction        | 0.00381       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0673       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.498         |\n",
      "|    n_updates            | 890           |\n",
      "|    policy_gradient_loss | -0.000312     |\n",
      "|    value_loss           | 0.998         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 636           |\n",
      "|    ep_rew_mean          | -0.364        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 423           |\n",
      "|    iterations           | 91            |\n",
      "|    time_elapsed         | 440           |\n",
      "|    total_timesteps      | 186368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020553128 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0654       |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.359         |\n",
      "|    n_updates            | 900           |\n",
      "|    policy_gradient_loss | -0.000179     |\n",
      "|    value_loss           | 0.719         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 652           |\n",
      "|    ep_rew_mean          | -0.346        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 423           |\n",
      "|    iterations           | 92            |\n",
      "|    time_elapsed         | 444           |\n",
      "|    total_timesteps      | 188416        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019899654 |\n",
      "|    clip_fraction        | 0.00264       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0482       |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.374         |\n",
      "|    n_updates            | 910           |\n",
      "|    policy_gradient_loss | -2.61e-05     |\n",
      "|    value_loss           | 0.748         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 660           |\n",
      "|    ep_rew_mean          | -0.338        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 424           |\n",
      "|    iterations           | 93            |\n",
      "|    time_elapsed         | 448           |\n",
      "|    total_timesteps      | 190464        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017644462 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0516       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.379         |\n",
      "|    n_updates            | 920           |\n",
      "|    policy_gradient_loss | -1.47e-05     |\n",
      "|    value_loss           | 0.758         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 676           |\n",
      "|    ep_rew_mean          | -0.33         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 425           |\n",
      "|    iterations           | 94            |\n",
      "|    time_elapsed         | 452           |\n",
      "|    total_timesteps      | 192512        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016239134 |\n",
      "|    clip_fraction        | 0.00205       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0581       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.202         |\n",
      "|    n_updates            | 930           |\n",
      "|    policy_gradient_loss | -0.000282     |\n",
      "|    value_loss           | 0.405         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 687           |\n",
      "|    ep_rew_mean          | -0.33         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 425           |\n",
      "|    iterations           | 95            |\n",
      "|    time_elapsed         | 457           |\n",
      "|    total_timesteps      | 194560        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023358839 |\n",
      "|    clip_fraction        | 0.00469       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0533       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.354         |\n",
      "|    n_updates            | 940           |\n",
      "|    policy_gradient_loss | -0.000286     |\n",
      "|    value_loss           | 0.71          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 704           |\n",
      "|    ep_rew_mean          | -0.32         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 425           |\n",
      "|    iterations           | 96            |\n",
      "|    time_elapsed         | 461           |\n",
      "|    total_timesteps      | 196608        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5818008e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0583       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.54          |\n",
      "|    n_updates            | 950           |\n",
      "|    policy_gradient_loss | 0.000259      |\n",
      "|    value_loss           | 1.08          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 717          |\n",
      "|    ep_rew_mean          | -0.32        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 426          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 466          |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.421015e-05 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0459      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.373        |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -7.24e-05    |\n",
      "|    value_loss           | 0.746        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 730           |\n",
      "|    ep_rew_mean          | -0.33         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 426           |\n",
      "|    iterations           | 98            |\n",
      "|    time_elapsed         | 470           |\n",
      "|    total_timesteps      | 200704        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4161691e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0489       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.373         |\n",
      "|    n_updates            | 970           |\n",
      "|    policy_gradient_loss | 8.15e-05      |\n",
      "|    value_loss           | 0.747         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 746           |\n",
      "|    ep_rew_mean          | -0.33         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 427           |\n",
      "|    iterations           | 99            |\n",
      "|    time_elapsed         | 474           |\n",
      "|    total_timesteps      | 202752        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2747823e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0499       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.191         |\n",
      "|    n_updates            | 980           |\n",
      "|    policy_gradient_loss | -6.47e-05     |\n",
      "|    value_loss           | 0.383         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 754           |\n",
      "|    ep_rew_mean          | -0.33         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 427           |\n",
      "|    iterations           | 100           |\n",
      "|    time_elapsed         | 478           |\n",
      "|    total_timesteps      | 204800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033457397 |\n",
      "|    clip_fraction        | 0.00313       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0497       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.339         |\n",
      "|    n_updates            | 990           |\n",
      "|    policy_gradient_loss | -0.000537     |\n",
      "|    value_loss           | 0.679         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 769           |\n",
      "|    ep_rew_mean          | -0.332        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 428           |\n",
      "|    iterations           | 101           |\n",
      "|    time_elapsed         | 482           |\n",
      "|    total_timesteps      | 206848        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2083906e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0459       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.373         |\n",
      "|    n_updates            | 1000          |\n",
      "|    policy_gradient_loss | -2.06e-05     |\n",
      "|    value_loss           | 0.746         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 779           |\n",
      "|    ep_rew_mean          | -0.36         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 428           |\n",
      "|    iterations           | 102           |\n",
      "|    time_elapsed         | 487           |\n",
      "|    total_timesteps      | 208896        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9998827e-05 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0485       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.191         |\n",
      "|    n_updates            | 1010          |\n",
      "|    policy_gradient_loss | -0.000103     |\n",
      "|    value_loss           | 0.382         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 799           |\n",
      "|    ep_rew_mean          | -0.37         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 429           |\n",
      "|    iterations           | 103           |\n",
      "|    time_elapsed         | 491           |\n",
      "|    total_timesteps      | 210944        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023949199 |\n",
      "|    clip_fraction        | 0.00112       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0448       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.372         |\n",
      "|    n_updates            | 1020          |\n",
      "|    policy_gradient_loss | -0.000239     |\n",
      "|    value_loss           | 0.746         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 799           |\n",
      "|    ep_rew_mean          | -0.37         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 430           |\n",
      "|    iterations           | 104           |\n",
      "|    time_elapsed         | 495           |\n",
      "|    total_timesteps      | 212992        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026691623 |\n",
      "|    clip_fraction        | 0.00205       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0355       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.362         |\n",
      "|    n_updates            | 1030          |\n",
      "|    policy_gradient_loss | -0.000238     |\n",
      "|    value_loss           | 0.725         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 818         |\n",
      "|    ep_rew_mean          | -0.37       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003027469 |\n",
      "|    clip_fraction        | 0.00352     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0507     |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 0.0186      |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    value_loss           | 0.0469      |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 830           |\n",
      "|    ep_rew_mean          | -0.262        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 431           |\n",
      "|    iterations           | 106           |\n",
      "|    time_elapsed         | 503           |\n",
      "|    total_timesteps      | 217088        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017321153 |\n",
      "|    clip_fraction        | 0.00283       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0768       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.563         |\n",
      "|    n_updates            | 1050          |\n",
      "|    policy_gradient_loss | 2.11e-05      |\n",
      "|    value_loss           | 1.13          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 846          |\n",
      "|    ep_rew_mean          | -0.252       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 431          |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 507          |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001583423 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0645      |\n",
      "|    explained_variance   | 0.0103       |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.181        |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.000187    |\n",
      "|    value_loss           | 0.363        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 855          |\n",
      "|    ep_rew_mean          | -0.262       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 432          |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 511          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.622148e-05 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0795      |\n",
      "|    explained_variance   | 0.0514       |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.522        |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.000426    |\n",
      "|    value_loss           | 1.06         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 857          |\n",
      "|    ep_rew_mean          | -0.34        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 432          |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 515          |\n",
      "|    total_timesteps      | 223232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002345453 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0748      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.373        |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -5.39e-05    |\n",
      "|    value_loss           | 0.747        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 872          |\n",
      "|    ep_rew_mean          | -0.304       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 433          |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 519          |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002644656 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.06        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.558        |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.000395    |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 877          |\n",
      "|    ep_rew_mean          | -0.304       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 433          |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 523          |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002927306 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0505      |\n",
      "|    explained_variance   | -0.00157     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.542        |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.000235    |\n",
      "|    value_loss           | 1.09         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 890          |\n",
      "|    ep_rew_mean          | -0.286       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 434          |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 527          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.398018e-05 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0565      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.399        |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | -0.000469    |\n",
      "|    value_loss           | 0.799        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 899          |\n",
      "|    ep_rew_mean          | -0.266       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 435          |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 531          |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.467271e-05 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0644      |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.38         |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -2.62e-06    |\n",
      "|    value_loss           | 0.76         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 907           |\n",
      "|    ep_rew_mean          | -0.284        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 435           |\n",
      "|    iterations           | 114           |\n",
      "|    time_elapsed         | 536           |\n",
      "|    total_timesteps      | 233472        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030369277 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0654       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.388         |\n",
      "|    n_updates            | 1130          |\n",
      "|    policy_gradient_loss | -0.000108     |\n",
      "|    value_loss           | 0.776         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 911          |\n",
      "|    ep_rew_mean          | -0.314       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 435          |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 540          |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.266559e-05 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0811      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.39         |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.000155    |\n",
      "|    value_loss           | 0.781        |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 913            |\n",
      "|    ep_rew_mean          | -0.342         |\n",
      "| time/                   |                |\n",
      "|    fps                  | 436            |\n",
      "|    iterations           | 116            |\n",
      "|    time_elapsed         | 544            |\n",
      "|    total_timesteps      | 237568         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000119855424 |\n",
      "|    clip_fraction        | 0.00757        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.0665        |\n",
      "|    explained_variance   | 0.00101        |\n",
      "|    learning_rate        | 0.0025         |\n",
      "|    loss                 | 0.708          |\n",
      "|    n_updates            | 1150           |\n",
      "|    policy_gradient_loss | -0.00068       |\n",
      "|    value_loss           | 1.44           |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 917          |\n",
      "|    ep_rew_mean          | -0.364       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 437          |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 548          |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.040677e-05 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0738      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.366        |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -6.66e-05    |\n",
      "|    value_loss           | 0.732        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 930           |\n",
      "|    ep_rew_mean          | -0.364        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 437           |\n",
      "|    iterations           | 118           |\n",
      "|    time_elapsed         | 552           |\n",
      "|    total_timesteps      | 241664        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020334232 |\n",
      "|    clip_fraction        | 0.00234       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0625       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.365         |\n",
      "|    n_updates            | 1170          |\n",
      "|    policy_gradient_loss | -0.000128     |\n",
      "|    value_loss           | 0.731         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 934           |\n",
      "|    ep_rew_mean          | -0.402        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 437           |\n",
      "|    iterations           | 119           |\n",
      "|    time_elapsed         | 556           |\n",
      "|    total_timesteps      | 243712        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8326129e-05 |\n",
      "|    clip_fraction        | 0.00176       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0672       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.378         |\n",
      "|    n_updates            | 1180          |\n",
      "|    policy_gradient_loss | -2.93e-05     |\n",
      "|    value_loss           | 0.755         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 942           |\n",
      "|    ep_rew_mean          | -0.44         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 438           |\n",
      "|    iterations           | 120           |\n",
      "|    time_elapsed         | 560           |\n",
      "|    total_timesteps      | 245760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027825654 |\n",
      "|    clip_fraction        | 0.00625       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0535       |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.353         |\n",
      "|    n_updates            | 1190          |\n",
      "|    policy_gradient_loss | -0.000488     |\n",
      "|    value_loss           | 0.708         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 948           |\n",
      "|    ep_rew_mean          | -0.5          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 438           |\n",
      "|    iterations           | 121           |\n",
      "|    time_elapsed         | 564           |\n",
      "|    total_timesteps      | 247808        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6566635e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0553       |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.548         |\n",
      "|    n_updates            | 1200          |\n",
      "|    policy_gradient_loss | 7.77e-05      |\n",
      "|    value_loss           | 1.1           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 947          |\n",
      "|    ep_rew_mean          | -0.52        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 439          |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 568          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010755169 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0585      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.184        |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    value_loss           | 0.374        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 935          |\n",
      "|    ep_rew_mean          | -0.512       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 439          |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 572          |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003899458 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0762      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.523        |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -6.78e-05    |\n",
      "|    value_loss           | 1.05         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 936           |\n",
      "|    ep_rew_mean          | -0.572        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 440           |\n",
      "|    iterations           | 124           |\n",
      "|    time_elapsed         | 577           |\n",
      "|    total_timesteps      | 253952        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012541204 |\n",
      "|    clip_fraction        | 0.00801       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0514       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.492         |\n",
      "|    n_updates            | 1230          |\n",
      "|    policy_gradient_loss | -0.00101      |\n",
      "|    value_loss           | 0.987         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 943           |\n",
      "|    ep_rew_mean          | -0.582        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 440           |\n",
      "|    iterations           | 125           |\n",
      "|    time_elapsed         | 581           |\n",
      "|    total_timesteps      | 256000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046725108 |\n",
      "|    clip_fraction        | 0.00439       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0506       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.361         |\n",
      "|    n_updates            | 1240          |\n",
      "|    policy_gradient_loss | -0.000533     |\n",
      "|    value_loss           | 0.724         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 943          |\n",
      "|    ep_rew_mean          | -0.582       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 440          |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 585          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003049897 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0447      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.339        |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | -0.000314    |\n",
      "|    value_loss           | 0.679        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 959          |\n",
      "|    ep_rew_mean          | -0.682       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 440          |\n",
      "|    iterations           | 127          |\n",
      "|    time_elapsed         | 589          |\n",
      "|    total_timesteps      | 260096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046287947 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0655      |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.00731      |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 0.0238       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 940         |\n",
      "|    ep_rew_mean          | -0.934      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 441         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 594         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001436725 |\n",
      "|    clip_fraction        | 0.00718     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.097      |\n",
      "|    explained_variance   | 0.031       |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 0.495       |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00107    |\n",
      "|    value_loss           | 1.02        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 942          |\n",
      "|    ep_rew_mean          | -1.01        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 441          |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 598          |\n",
      "|    total_timesteps      | 264192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063273152 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.073       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.847        |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 1.7          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 945         |\n",
      "|    ep_rew_mean          | -1.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 441         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 602         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000773449 |\n",
      "|    clip_fraction        | 0.004       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.068      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 0.347       |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.000972   |\n",
      "|    value_loss           | 0.698       |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 949           |\n",
      "|    ep_rew_mean          | -1.03         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 442           |\n",
      "|    iterations           | 131           |\n",
      "|    time_elapsed         | 606           |\n",
      "|    total_timesteps      | 268288        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020095252 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0607       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.355         |\n",
      "|    n_updates            | 1300          |\n",
      "|    policy_gradient_loss | 0.000104      |\n",
      "|    value_loss           | 0.713         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 952           |\n",
      "|    ep_rew_mean          | -1.04         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 442           |\n",
      "|    iterations           | 132           |\n",
      "|    time_elapsed         | 610           |\n",
      "|    total_timesteps      | 270336        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021488086 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0618       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.374         |\n",
      "|    n_updates            | 1310          |\n",
      "|    policy_gradient_loss | -6.89e-05     |\n",
      "|    value_loss           | 0.747         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 949           |\n",
      "|    ep_rew_mean          | -1.06         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 442           |\n",
      "|    iterations           | 133           |\n",
      "|    time_elapsed         | 614           |\n",
      "|    total_timesteps      | 272384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010985753 |\n",
      "|    clip_fraction        | 0.00381       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0596       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.524         |\n",
      "|    n_updates            | 1320          |\n",
      "|    policy_gradient_loss | -0.000329     |\n",
      "|    value_loss           | 1.05          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 945           |\n",
      "|    ep_rew_mean          | -1.05         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 443           |\n",
      "|    iterations           | 134           |\n",
      "|    time_elapsed         | 619           |\n",
      "|    total_timesteps      | 274432        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4902325e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0641       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.361         |\n",
      "|    n_updates            | 1330          |\n",
      "|    policy_gradient_loss | 3.36e-05      |\n",
      "|    value_loss           | 0.722         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 949           |\n",
      "|    ep_rew_mean          | -1.07         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 443           |\n",
      "|    iterations           | 135           |\n",
      "|    time_elapsed         | 623           |\n",
      "|    total_timesteps      | 276480        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012078832 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0663       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.383         |\n",
      "|    n_updates            | 1340          |\n",
      "|    policy_gradient_loss | -7.49e-05     |\n",
      "|    value_loss           | 0.766         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 951           |\n",
      "|    ep_rew_mean          | -1.07         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 443           |\n",
      "|    iterations           | 136           |\n",
      "|    time_elapsed         | 627           |\n",
      "|    total_timesteps      | 278528        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016288992 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0726       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.545         |\n",
      "|    n_updates            | 1350          |\n",
      "|    policy_gradient_loss | -7.75e-05     |\n",
      "|    value_loss           | 1.09          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 941          |\n",
      "|    ep_rew_mean          | -1.07        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 444          |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 631          |\n",
      "|    total_timesteps      | 280576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003246719 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0665      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.202        |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.000204    |\n",
      "|    value_loss           | 0.405        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 938           |\n",
      "|    ep_rew_mean          | -1.09         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 444           |\n",
      "|    iterations           | 138           |\n",
      "|    time_elapsed         | 635           |\n",
      "|    total_timesteps      | 282624        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018691074 |\n",
      "|    clip_fraction        | 0.00264       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0661       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.548         |\n",
      "|    n_updates            | 1370          |\n",
      "|    policy_gradient_loss | -0.000146     |\n",
      "|    value_loss           | 1.1           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 924           |\n",
      "|    ep_rew_mean          | -1.09         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 444           |\n",
      "|    iterations           | 139           |\n",
      "|    time_elapsed         | 640           |\n",
      "|    total_timesteps      | 284672        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5266374e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0654       |\n",
      "|    explained_variance   | 0.105         |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.325         |\n",
      "|    n_updates            | 1380          |\n",
      "|    policy_gradient_loss | -6.24e-05     |\n",
      "|    value_loss           | 0.661         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 926           |\n",
      "|    ep_rew_mean          | -1.15         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 445           |\n",
      "|    iterations           | 140           |\n",
      "|    time_elapsed         | 644           |\n",
      "|    total_timesteps      | 286720        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2688218e-05 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0599       |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.573         |\n",
      "|    n_updates            | 1390          |\n",
      "|    policy_gradient_loss | -4.01e-05     |\n",
      "|    value_loss           | 1.15          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 919           |\n",
      "|    ep_rew_mean          | -1.18         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 445           |\n",
      "|    iterations           | 141           |\n",
      "|    time_elapsed         | 648           |\n",
      "|    total_timesteps      | 288768        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014877244 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0625       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.571         |\n",
      "|    n_updates            | 1400          |\n",
      "|    policy_gradient_loss | -7.03e-05     |\n",
      "|    value_loss           | 1.14          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 907           |\n",
      "|    ep_rew_mean          | -1.17         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 445           |\n",
      "|    iterations           | 142           |\n",
      "|    time_elapsed         | 652           |\n",
      "|    total_timesteps      | 290816        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071438897 |\n",
      "|    clip_fraction        | 0.0061        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0577       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.514         |\n",
      "|    n_updates            | 1410          |\n",
      "|    policy_gradient_loss | -0.00039      |\n",
      "|    value_loss           | 1.03          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 901           |\n",
      "|    ep_rew_mean          | -1.16         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 446           |\n",
      "|    iterations           | 143           |\n",
      "|    time_elapsed         | 656           |\n",
      "|    total_timesteps      | 292864        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019676032 |\n",
      "|    clip_fraction        | 0.00215       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0596       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.353         |\n",
      "|    n_updates            | 1420          |\n",
      "|    policy_gradient_loss | -0.00107      |\n",
      "|    value_loss           | 0.709         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 900           |\n",
      "|    ep_rew_mean          | -1.16         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 446           |\n",
      "|    iterations           | 144           |\n",
      "|    time_elapsed         | 660           |\n",
      "|    total_timesteps      | 294912        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012668004 |\n",
      "|    clip_fraction        | 0.00205       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.066        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.384         |\n",
      "|    n_updates            | 1430          |\n",
      "|    policy_gradient_loss | -0.000232     |\n",
      "|    value_loss           | 0.769         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 894           |\n",
      "|    ep_rew_mean          | -1.18         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 446           |\n",
      "|    iterations           | 145           |\n",
      "|    time_elapsed         | 664           |\n",
      "|    total_timesteps      | 296960        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019644026 |\n",
      "|    clip_fraction        | 0.00103       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0685       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.391         |\n",
      "|    n_updates            | 1440          |\n",
      "|    policy_gradient_loss | -9.89e-05     |\n",
      "|    value_loss           | 0.783         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 876          |\n",
      "|    ep_rew_mean          | -1.17        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 447          |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 668          |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002588236 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0807      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.39         |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | -0.000146    |\n",
      "|    value_loss           | 0.781        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 858           |\n",
      "|    ep_rew_mean          | -1.17         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 447           |\n",
      "|    iterations           | 147           |\n",
      "|    time_elapsed         | 672           |\n",
      "|    total_timesteps      | 301056        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5300175e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0946       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.555         |\n",
      "|    n_updates            | 1460          |\n",
      "|    policy_gradient_loss | 5.08e-05      |\n",
      "|    value_loss           | 1.11          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 842           |\n",
      "|    ep_rew_mean          | -1.35         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 447           |\n",
      "|    iterations           | 148           |\n",
      "|    time_elapsed         | 676           |\n",
      "|    total_timesteps      | 303104        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013189996 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0862       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.734         |\n",
      "|    n_updates            | 1470          |\n",
      "|    policy_gradient_loss | 5.58e-06      |\n",
      "|    value_loss           | 1.47          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 839           |\n",
      "|    ep_rew_mean          | -1.39         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 448           |\n",
      "|    iterations           | 149           |\n",
      "|    time_elapsed         | 680           |\n",
      "|    total_timesteps      | 305152        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027197815 |\n",
      "|    clip_fraction        | 0.00532       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0737       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.736         |\n",
      "|    n_updates            | 1480          |\n",
      "|    policy_gradient_loss | -0.000589     |\n",
      "|    value_loss           | 1.48          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 854           |\n",
      "|    ep_rew_mean          | -1.35         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 448           |\n",
      "|    iterations           | 150           |\n",
      "|    time_elapsed         | 685           |\n",
      "|    total_timesteps      | 307200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046537758 |\n",
      "|    clip_fraction        | 0.00254       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0824       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.205         |\n",
      "|    n_updates            | 1490          |\n",
      "|    policy_gradient_loss | -0.000543     |\n",
      "|    value_loss           | 0.412         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 850          |\n",
      "|    ep_rew_mean          | -1.41        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 448          |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 689          |\n",
      "|    total_timesteps      | 309248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.700098e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0861      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.368        |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | 1.31e-05     |\n",
      "|    value_loss           | 0.737        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 848           |\n",
      "|    ep_rew_mean          | -1.52         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 448           |\n",
      "|    iterations           | 152           |\n",
      "|    time_elapsed         | 693           |\n",
      "|    total_timesteps      | 311296        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040386923 |\n",
      "|    clip_fraction        | 0.00557       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0683       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.541         |\n",
      "|    n_updates            | 1510          |\n",
      "|    policy_gradient_loss | -0.0005       |\n",
      "|    value_loss           | 1.09          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 854          |\n",
      "|    ep_rew_mean          | -1.59        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 448          |\n",
      "|    iterations           | 153          |\n",
      "|    time_elapsed         | 697          |\n",
      "|    total_timesteps      | 313344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021868541 |\n",
      "|    clip_fraction        | 0.00801      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0555      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.509        |\n",
      "|    n_updates            | 1520         |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 858          |\n",
      "|    ep_rew_mean          | -1.63        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 449          |\n",
      "|    iterations           | 154          |\n",
      "|    time_elapsed         | 702          |\n",
      "|    total_timesteps      | 315392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002377801 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0457      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.173        |\n",
      "|    n_updates            | 1530         |\n",
      "|    policy_gradient_loss | -0.00096     |\n",
      "|    value_loss           | 0.349        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 862           |\n",
      "|    ep_rew_mean          | -1.69         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 449           |\n",
      "|    iterations           | 155           |\n",
      "|    time_elapsed         | 706           |\n",
      "|    total_timesteps      | 317440        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067260594 |\n",
      "|    clip_fraction        | 0.00283       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0466       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.348         |\n",
      "|    n_updates            | 1540          |\n",
      "|    policy_gradient_loss | -0.000515     |\n",
      "|    value_loss           | 0.697         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 875           |\n",
      "|    ep_rew_mean          | -1.78         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 449           |\n",
      "|    iterations           | 156           |\n",
      "|    time_elapsed         | 710           |\n",
      "|    total_timesteps      | 319488        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070008123 |\n",
      "|    clip_fraction        | 0.00215       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0475       |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.17          |\n",
      "|    n_updates            | 1550          |\n",
      "|    policy_gradient_loss | -0.00169      |\n",
      "|    value_loss           | 0.345         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 877           |\n",
      "|    ep_rew_mean          | -1.8          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 449           |\n",
      "|    iterations           | 157           |\n",
      "|    time_elapsed         | 714           |\n",
      "|    total_timesteps      | 321536        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029863746 |\n",
      "|    clip_fraction        | 0.00171       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0595       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.346         |\n",
      "|    n_updates            | 1560          |\n",
      "|    policy_gradient_loss | -0.000322     |\n",
      "|    value_loss           | 0.694         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 870           |\n",
      "|    ep_rew_mean          | -2.02         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 450           |\n",
      "|    iterations           | 158           |\n",
      "|    time_elapsed         | 719           |\n",
      "|    total_timesteps      | 323584        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027716288 |\n",
      "|    clip_fraction        | 0.00366       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0497       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.353         |\n",
      "|    n_updates            | 1570          |\n",
      "|    policy_gradient_loss | -0.000268     |\n",
      "|    value_loss           | 0.706         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 879          |\n",
      "|    ep_rew_mean          | -2.07        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 450          |\n",
      "|    iterations           | 159          |\n",
      "|    time_elapsed         | 723          |\n",
      "|    total_timesteps      | 325632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019873993 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0473      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.644        |\n",
      "|    n_updates            | 1580         |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 883          |\n",
      "|    ep_rew_mean          | -2.11        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 450          |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 727          |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005573209 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0328      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.174        |\n",
      "|    n_updates            | 1590         |\n",
      "|    policy_gradient_loss | -0.000614    |\n",
      "|    value_loss           | 0.352        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 894          |\n",
      "|    ep_rew_mean          | -2.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 450          |\n",
      "|    iterations           | 161          |\n",
      "|    time_elapsed         | 731          |\n",
      "|    total_timesteps      | 329728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006648215 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0377      |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.168        |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 0.341        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 895           |\n",
      "|    ep_rew_mean          | -2.14         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 450           |\n",
      "|    iterations           | 162           |\n",
      "|    time_elapsed         | 735           |\n",
      "|    total_timesteps      | 331776        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8334477e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0423       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.177         |\n",
      "|    n_updates            | 1610          |\n",
      "|    policy_gradient_loss | 0.000181      |\n",
      "|    value_loss           | 0.355         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 909           |\n",
      "|    ep_rew_mean          | -2.21         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 451           |\n",
      "|    iterations           | 163           |\n",
      "|    time_elapsed         | 739           |\n",
      "|    total_timesteps      | 333824        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033224505 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0349       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.165         |\n",
      "|    n_updates            | 1620          |\n",
      "|    policy_gradient_loss | -0.000706     |\n",
      "|    value_loss           | 0.332         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 931           |\n",
      "|    ep_rew_mean          | -2.21         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 451           |\n",
      "|    iterations           | 164           |\n",
      "|    time_elapsed         | 744           |\n",
      "|    total_timesteps      | 335872        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012463168 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0303       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.173         |\n",
      "|    n_updates            | 1630          |\n",
      "|    policy_gradient_loss | -0.000247     |\n",
      "|    value_loss           | 0.346         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 931          |\n",
      "|    ep_rew_mean          | -2.21        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 451          |\n",
      "|    iterations           | 165          |\n",
      "|    time_elapsed         | 748          |\n",
      "|    total_timesteps      | 337920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.687483e-05 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0259      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.182        |\n",
      "|    n_updates            | 1640         |\n",
      "|    policy_gradient_loss | -0.000157    |\n",
      "|    value_loss           | 0.365        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 949          |\n",
      "|    ep_rew_mean          | -2.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 451          |\n",
      "|    iterations           | 166          |\n",
      "|    time_elapsed         | 752          |\n",
      "|    total_timesteps      | 339968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042862883 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0447      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.00887      |\n",
      "|    n_updates            | 1650         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 0.0259       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 950           |\n",
      "|    ep_rew_mean          | -2.2          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 451           |\n",
      "|    iterations           | 167           |\n",
      "|    time_elapsed         | 756           |\n",
      "|    total_timesteps      | 342016        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011180749 |\n",
      "|    clip_fraction        | 0.000684      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0853       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.423         |\n",
      "|    n_updates            | 1660          |\n",
      "|    policy_gradient_loss | 0.000183      |\n",
      "|    value_loss           | 0.847         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 959          |\n",
      "|    ep_rew_mean          | -2.27        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 452          |\n",
      "|    iterations           | 168          |\n",
      "|    time_elapsed         | 760          |\n",
      "|    total_timesteps      | 344064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015546109 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0552      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.331        |\n",
      "|    n_updates            | 1670         |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    value_loss           | 0.67         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 966           |\n",
      "|    ep_rew_mean          | -2.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 452           |\n",
      "|    iterations           | 169           |\n",
      "|    time_elapsed         | 765           |\n",
      "|    total_timesteps      | 346112        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041073936 |\n",
      "|    clip_fraction        | 0.00103       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0444       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.175         |\n",
      "|    n_updates            | 1680          |\n",
      "|    policy_gradient_loss | -0.000807     |\n",
      "|    value_loss           | 0.354         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 966           |\n",
      "|    ep_rew_mean          | -2.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 452           |\n",
      "|    iterations           | 170           |\n",
      "|    time_elapsed         | 769           |\n",
      "|    total_timesteps      | 348160        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025250664 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0489       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.352         |\n",
      "|    n_updates            | 1690          |\n",
      "|    policy_gradient_loss | -7.92e-05     |\n",
      "|    value_loss           | 0.705         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 969         |\n",
      "|    ep_rew_mean          | -2.32       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 452         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 773         |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004378509 |\n",
      "|    clip_fraction        | 0.00273     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0678     |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 0.0122      |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    value_loss           | 0.0338      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 932          |\n",
      "|    ep_rew_mean          | -2.49        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 453          |\n",
      "|    iterations           | 172          |\n",
      "|    time_elapsed         | 777          |\n",
      "|    total_timesteps      | 352256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010968061 |\n",
      "|    clip_fraction        | 0.00713      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.114       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.719        |\n",
      "|    n_updates            | 1710         |\n",
      "|    policy_gradient_loss | -0.000437    |\n",
      "|    value_loss           | 1.44         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 929          |\n",
      "|    ep_rew_mean          | -2.45        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 453          |\n",
      "|    iterations           | 173          |\n",
      "|    time_elapsed         | 781          |\n",
      "|    total_timesteps      | 354304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015380803 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.107       |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.859        |\n",
      "|    n_updates            | 1720         |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    value_loss           | 1.73         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 924          |\n",
      "|    ep_rew_mean          | -2.37        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 453          |\n",
      "|    iterations           | 174          |\n",
      "|    time_elapsed         | 785          |\n",
      "|    total_timesteps      | 356352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004342699 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0911      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.827        |\n",
      "|    n_updates            | 1730         |\n",
      "|    policy_gradient_loss | -0.000636    |\n",
      "|    value_loss           | 1.66         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 932           |\n",
      "|    ep_rew_mean          | -2.5          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 453           |\n",
      "|    iterations           | 175           |\n",
      "|    time_elapsed         | 789           |\n",
      "|    total_timesteps      | 358400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015770784 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.1          |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.349         |\n",
      "|    n_updates            | 1740          |\n",
      "|    policy_gradient_loss | -9.33e-05     |\n",
      "|    value_loss           | 0.699         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 913          |\n",
      "|    ep_rew_mean          | -2.59        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 453          |\n",
      "|    iterations           | 176          |\n",
      "|    time_elapsed         | 794          |\n",
      "|    total_timesteps      | 360448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008398234 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0817      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.49         |\n",
      "|    n_updates            | 1750         |\n",
      "|    policy_gradient_loss | -0.000507    |\n",
      "|    value_loss           | 0.983        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 919          |\n",
      "|    ep_rew_mean          | -2.64        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 454          |\n",
      "|    iterations           | 177          |\n",
      "|    time_elapsed         | 798          |\n",
      "|    total_timesteps      | 362496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005570053 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0744      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.501        |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.000344    |\n",
      "|    value_loss           | 1            |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 921           |\n",
      "|    ep_rew_mean          | -2.64         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 454           |\n",
      "|    iterations           | 178           |\n",
      "|    time_elapsed         | 802           |\n",
      "|    total_timesteps      | 364544        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015950494 |\n",
      "|    clip_fraction        | 0.00303       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0579       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.344         |\n",
      "|    n_updates            | 1770          |\n",
      "|    policy_gradient_loss | -0.000368     |\n",
      "|    value_loss           | 0.689         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 919           |\n",
      "|    ep_rew_mean          | -2.8          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 454           |\n",
      "|    iterations           | 179           |\n",
      "|    time_elapsed         | 806           |\n",
      "|    total_timesteps      | 366592        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026029194 |\n",
      "|    clip_fraction        | 0.000684      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0644       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.183         |\n",
      "|    n_updates            | 1780          |\n",
      "|    policy_gradient_loss | -0.000167     |\n",
      "|    value_loss           | 0.366         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 916           |\n",
      "|    ep_rew_mean          | -2.77         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 454           |\n",
      "|    iterations           | 180           |\n",
      "|    time_elapsed         | 810           |\n",
      "|    total_timesteps      | 368640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083860924 |\n",
      "|    clip_fraction        | 0.00239       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0678       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.676         |\n",
      "|    n_updates            | 1790          |\n",
      "|    policy_gradient_loss | -0.000743     |\n",
      "|    value_loss           | 1.35          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 914           |\n",
      "|    ep_rew_mean          | -2.85         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 454           |\n",
      "|    iterations           | 181           |\n",
      "|    time_elapsed         | 814           |\n",
      "|    total_timesteps      | 370688        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024792564 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0736       |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.359         |\n",
      "|    n_updates            | 1800          |\n",
      "|    policy_gradient_loss | -4.68e-05     |\n",
      "|    value_loss           | 0.718         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 914           |\n",
      "|    ep_rew_mean          | -2.98         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 454           |\n",
      "|    iterations           | 182           |\n",
      "|    time_elapsed         | 819           |\n",
      "|    total_timesteps      | 372736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018360707 |\n",
      "|    clip_fraction        | 0.00425       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0702       |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.352         |\n",
      "|    n_updates            | 1810          |\n",
      "|    policy_gradient_loss | -0.000261     |\n",
      "|    value_loss           | 0.705         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 906          |\n",
      "|    ep_rew_mean          | -3.15        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 455          |\n",
      "|    iterations           | 183          |\n",
      "|    time_elapsed         | 823          |\n",
      "|    total_timesteps      | 374784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016532793 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0678      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.516        |\n",
      "|    n_updates            | 1820         |\n",
      "|    policy_gradient_loss | -0.000701    |\n",
      "|    value_loss           | 1.03         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 915          |\n",
      "|    ep_rew_mean          | -3.23        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 454          |\n",
      "|    iterations           | 184          |\n",
      "|    time_elapsed         | 828          |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009226118 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0544      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.48         |\n",
      "|    n_updates            | 1830         |\n",
      "|    policy_gradient_loss | -0.000815    |\n",
      "|    value_loss           | 0.964        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 924           |\n",
      "|    ep_rew_mean          | -3.2          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 455           |\n",
      "|    iterations           | 185           |\n",
      "|    time_elapsed         | 832           |\n",
      "|    total_timesteps      | 378880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034122536 |\n",
      "|    clip_fraction        | 0.0022        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0415       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.162         |\n",
      "|    n_updates            | 1840          |\n",
      "|    policy_gradient_loss | -0.000808     |\n",
      "|    value_loss           | 0.326         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 939          |\n",
      "|    ep_rew_mean          | -3.24        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 455          |\n",
      "|    iterations           | 186          |\n",
      "|    time_elapsed         | 836          |\n",
      "|    total_timesteps      | 380928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004811445 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0409      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.18         |\n",
      "|    n_updates            | 1850         |\n",
      "|    policy_gradient_loss | -0.00086     |\n",
      "|    value_loss           | 0.362        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 947          |\n",
      "|    ep_rew_mean          | -3.34        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 455          |\n",
      "|    iterations           | 187          |\n",
      "|    time_elapsed         | 841          |\n",
      "|    total_timesteps      | 382976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007676306 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.051       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.168        |\n",
      "|    n_updates            | 1860         |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    value_loss           | 0.338        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 955          |\n",
      "|    ep_rew_mean          | -3.36        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 455          |\n",
      "|    iterations           | 188          |\n",
      "|    time_elapsed         | 845          |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014850774 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0416      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.324        |\n",
      "|    n_updates            | 1870         |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    value_loss           | 0.651        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 955           |\n",
      "|    ep_rew_mean          | -3.36         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 455           |\n",
      "|    iterations           | 189           |\n",
      "|    time_elapsed         | 849           |\n",
      "|    total_timesteps      | 387072        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012560748 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0304       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.178         |\n",
      "|    n_updates            | 1880          |\n",
      "|    policy_gradient_loss | -8.13e-05     |\n",
      "|    value_loss           | 0.356         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 961         |\n",
      "|    ep_rew_mean          | -3.52       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 455         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004376838 |\n",
      "|    clip_fraction        | 0.00278     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0488     |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 0.0116      |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    value_loss           | 0.0295      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 960          |\n",
      "|    ep_rew_mean          | -3.52        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 456          |\n",
      "|    iterations           | 191          |\n",
      "|    time_elapsed         | 857          |\n",
      "|    total_timesteps      | 391168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009182732 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0841      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.669        |\n",
      "|    n_updates            | 1900         |\n",
      "|    policy_gradient_loss | -0.000809    |\n",
      "|    value_loss           | 1.34         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 959           |\n",
      "|    ep_rew_mean          | -3.52         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 456           |\n",
      "|    iterations           | 192           |\n",
      "|    time_elapsed         | 862           |\n",
      "|    total_timesteps      | 393216        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021170118 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0689       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.356         |\n",
      "|    n_updates            | 1910          |\n",
      "|    policy_gradient_loss | -5.7e-05      |\n",
      "|    value_loss           | 0.712         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 965          |\n",
      "|    ep_rew_mean          | -3.54        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 456          |\n",
      "|    iterations           | 193          |\n",
      "|    time_elapsed         | 866          |\n",
      "|    total_timesteps      | 395264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.387328e-05 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0544      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.512        |\n",
      "|    n_updates            | 1920         |\n",
      "|    policy_gradient_loss | -0.00037     |\n",
      "|    value_loss           | 1.03         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 974          |\n",
      "|    ep_rew_mean          | -3.56        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 456          |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 870          |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002432788 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0568      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.354        |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.00021     |\n",
      "|    value_loss           | 0.709        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 985           |\n",
      "|    ep_rew_mean          | -3.71         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 456           |\n",
      "|    iterations           | 195           |\n",
      "|    time_elapsed         | 874           |\n",
      "|    total_timesteps      | 399360        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021956975 |\n",
      "|    clip_fraction        | 0.00107       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.055        |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.196         |\n",
      "|    n_updates            | 1940          |\n",
      "|    policy_gradient_loss | -0.000235     |\n",
      "|    value_loss           | 0.392         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 985          |\n",
      "|    ep_rew_mean          | -3.71        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 456          |\n",
      "|    iterations           | 196          |\n",
      "|    time_elapsed         | 878          |\n",
      "|    total_timesteps      | 401408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015124814 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0484      |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.5          |\n",
      "|    n_updates            | 1950         |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -3.65       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 456         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 882         |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002957984 |\n",
      "|    clip_fraction        | 0.00381     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0573     |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    value_loss           | 0.0333      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -3.73        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 198          |\n",
      "|    time_elapsed         | 887          |\n",
      "|    total_timesteps      | 405504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005728019 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0846      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.521        |\n",
      "|    n_updates            | 1970         |\n",
      "|    policy_gradient_loss | -0.000169    |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -3.85        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 891          |\n",
      "|    total_timesteps      | 407552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016902217 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0613      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.503        |\n",
      "|    n_updates            | 1980         |\n",
      "|    policy_gradient_loss | -0.000909    |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -3.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 895          |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007672173 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.332        |\n",
      "|    n_updates            | 1990         |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 0.666        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.02e+03      |\n",
      "|    ep_rew_mean          | -3.81         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 457           |\n",
      "|    iterations           | 201           |\n",
      "|    time_elapsed         | 900           |\n",
      "|    total_timesteps      | 411648        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1184486e-05 |\n",
      "|    clip_fraction        | 0.0022        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.045        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.189         |\n",
      "|    n_updates            | 2000          |\n",
      "|    policy_gradient_loss | -0.000173     |\n",
      "|    value_loss           | 0.378         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -3.81        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 202          |\n",
      "|    time_elapsed         | 904          |\n",
      "|    total_timesteps      | 413696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.937155e-05 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.046       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.187        |\n",
      "|    n_updates            | 2010         |\n",
      "|    policy_gradient_loss | -0.00013     |\n",
      "|    value_loss           | 0.374        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.77        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 908          |\n",
      "|    total_timesteps      | 415744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.640708e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0476      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.179        |\n",
      "|    n_updates            | 2020         |\n",
      "|    policy_gradient_loss | -0.000122    |\n",
      "|    value_loss           | 0.358        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.05e+03     |\n",
      "|    ep_rew_mean          | -3.75        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 204          |\n",
      "|    time_elapsed         | 912          |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006617552 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0439      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.184        |\n",
      "|    n_updates            | 2030         |\n",
      "|    policy_gradient_loss | -0.000981    |\n",
      "|    value_loss           | 0.373        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.05e+03      |\n",
      "|    ep_rew_mean          | -3.73         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 457           |\n",
      "|    iterations           | 205           |\n",
      "|    time_elapsed         | 916           |\n",
      "|    total_timesteps      | 419840        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048081088 |\n",
      "|    clip_fraction        | 0.0022        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0601       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.352         |\n",
      "|    n_updates            | 2040          |\n",
      "|    policy_gradient_loss | -0.000213     |\n",
      "|    value_loss           | 0.704         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -3.67         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 458           |\n",
      "|    iterations           | 206           |\n",
      "|    time_elapsed         | 920           |\n",
      "|    total_timesteps      | 421888        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5500765e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0557       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.189         |\n",
      "|    n_updates            | 2050          |\n",
      "|    policy_gradient_loss | -0.000109     |\n",
      "|    value_loss           | 0.378         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -3.61        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 207          |\n",
      "|    time_elapsed         | 925          |\n",
      "|    total_timesteps      | 423936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.718037e-05 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0656      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.367        |\n",
      "|    n_updates            | 2060         |\n",
      "|    policy_gradient_loss | 3.47e-05     |\n",
      "|    value_loss           | 0.733        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.62        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 208          |\n",
      "|    time_elapsed         | 929          |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009948385 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0555      |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.516        |\n",
      "|    n_updates            | 2070         |\n",
      "|    policy_gradient_loss | -0.000635    |\n",
      "|    value_loss           | 1.03         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.56        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 209          |\n",
      "|    time_elapsed         | 933          |\n",
      "|    total_timesteps      | 428032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004658076 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0528      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.367        |\n",
      "|    n_updates            | 2080         |\n",
      "|    policy_gradient_loss | -0.0003      |\n",
      "|    value_loss           | 0.734        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -3.41         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 458           |\n",
      "|    iterations           | 210           |\n",
      "|    time_elapsed         | 937           |\n",
      "|    total_timesteps      | 430080        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038827266 |\n",
      "|    clip_fraction        | 0.00352       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0562       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.36          |\n",
      "|    n_updates            | 2090          |\n",
      "|    policy_gradient_loss | -0.000958     |\n",
      "|    value_loss           | 0.722         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -3.42        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 941          |\n",
      "|    total_timesteps      | 432128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.470653e-05 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0446      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.487        |\n",
      "|    n_updates            | 2100         |\n",
      "|    policy_gradient_loss | -0.000927    |\n",
      "|    value_loss           | 0.976        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.01e+03      |\n",
      "|    ep_rew_mean          | -3.33         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 459           |\n",
      "|    iterations           | 212           |\n",
      "|    time_elapsed         | 945           |\n",
      "|    total_timesteps      | 434176        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5461137e-05 |\n",
      "|    clip_fraction        | 0.00293       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0634       |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.193         |\n",
      "|    n_updates            | 2110          |\n",
      "|    policy_gradient_loss | -0.000108     |\n",
      "|    value_loss           | 0.388         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 982           |\n",
      "|    ep_rew_mean          | -3.33         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 459           |\n",
      "|    iterations           | 213           |\n",
      "|    time_elapsed         | 949           |\n",
      "|    total_timesteps      | 436224        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038015042 |\n",
      "|    clip_fraction        | 0.00498       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0469       |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.356         |\n",
      "|    n_updates            | 2120          |\n",
      "|    policy_gradient_loss | -0.000472     |\n",
      "|    value_loss           | 0.714         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 990         |\n",
      "|    ep_rew_mean          | -3.31       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 954         |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.63914e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0486     |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 0.353       |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | 8.63e-05    |\n",
      "|    value_loss           | 0.706       |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 992           |\n",
      "|    ep_rew_mean          | -3.25         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 459           |\n",
      "|    iterations           | 215           |\n",
      "|    time_elapsed         | 958           |\n",
      "|    total_timesteps      | 440320        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030779745 |\n",
      "|    clip_fraction        | 0.00313       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.047        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.206         |\n",
      "|    n_updates            | 2140          |\n",
      "|    policy_gradient_loss | -0.000186     |\n",
      "|    value_loss           | 0.412         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 995           |\n",
      "|    ep_rew_mean          | -3.17         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 459           |\n",
      "|    iterations           | 216           |\n",
      "|    time_elapsed         | 962           |\n",
      "|    total_timesteps      | 442368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3158146e-05 |\n",
      "|    clip_fraction        | 0.00342       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0409       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.365         |\n",
      "|    n_updates            | 2150          |\n",
      "|    policy_gradient_loss | -1.21e-05     |\n",
      "|    value_loss           | 0.731         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 989          |\n",
      "|    ep_rew_mean          | -3.19        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 217          |\n",
      "|    time_elapsed         | 966          |\n",
      "|    total_timesteps      | 444416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.712678e-05 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0504      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.189        |\n",
      "|    n_updates            | 2160         |\n",
      "|    policy_gradient_loss | -7.96e-05    |\n",
      "|    value_loss           | 0.379        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 995           |\n",
      "|    ep_rew_mean          | -3.19         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 460           |\n",
      "|    iterations           | 218           |\n",
      "|    time_elapsed         | 970           |\n",
      "|    total_timesteps      | 446464        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013222493 |\n",
      "|    clip_fraction        | 0.00449       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0429       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.359         |\n",
      "|    n_updates            | 2170          |\n",
      "|    policy_gradient_loss | -0.000877     |\n",
      "|    value_loss           | 0.72          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 991           |\n",
      "|    ep_rew_mean          | -3.28         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 460           |\n",
      "|    iterations           | 219           |\n",
      "|    time_elapsed         | 974           |\n",
      "|    total_timesteps      | 448512        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035977722 |\n",
      "|    clip_fraction        | 0.00215       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0451       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.179         |\n",
      "|    n_updates            | 2180          |\n",
      "|    policy_gradient_loss | -0.000327     |\n",
      "|    value_loss           | 0.36          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 991          |\n",
      "|    ep_rew_mean          | -3.28        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 460          |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 979          |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013188957 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0305      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.524        |\n",
      "|    n_updates            | 2190         |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    value_loss           | 1.05         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -3.14        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 460          |\n",
      "|    iterations           | 221          |\n",
      "|    time_elapsed         | 983          |\n",
      "|    total_timesteps      | 452608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056068143 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0505      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.0198       |\n",
      "|    n_updates            | 2200         |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    value_loss           | 0.0504       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | -3.01        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 460          |\n",
      "|    iterations           | 222          |\n",
      "|    time_elapsed         | 987          |\n",
      "|    total_timesteps      | 454656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007403555 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.075       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.504        |\n",
      "|    n_updates            | 2210         |\n",
      "|    policy_gradient_loss | -0.000163    |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -2.95        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 460          |\n",
      "|    iterations           | 223          |\n",
      "|    time_elapsed         | 991          |\n",
      "|    total_timesteps      | 456704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.396742e-05 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0675      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.556        |\n",
      "|    n_updates            | 2220         |\n",
      "|    policy_gradient_loss | -8.49e-05    |\n",
      "|    value_loss           | 1.11         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.05e+03      |\n",
      "|    ep_rew_mean          | -2.83         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 460           |\n",
      "|    iterations           | 224           |\n",
      "|    time_elapsed         | 995           |\n",
      "|    total_timesteps      | 458752        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017941801 |\n",
      "|    clip_fraction        | 0.00605       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.057        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.338         |\n",
      "|    n_updates            | 2230          |\n",
      "|    policy_gradient_loss | -0.000717     |\n",
      "|    value_loss           | 0.678         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.06e+03      |\n",
      "|    ep_rew_mean          | -2.88         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 460           |\n",
      "|    iterations           | 225           |\n",
      "|    time_elapsed         | 999           |\n",
      "|    total_timesteps      | 460800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6923063e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0685       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.367         |\n",
      "|    n_updates            | 2240          |\n",
      "|    policy_gradient_loss | 7.49e-05      |\n",
      "|    value_loss           | 0.734         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.05e+03      |\n",
      "|    ep_rew_mean          | -2.82         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 460           |\n",
      "|    iterations           | 226           |\n",
      "|    time_elapsed         | 1004          |\n",
      "|    total_timesteps      | 462848        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022574182 |\n",
      "|    clip_fraction        | 0.00317       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.062        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.366         |\n",
      "|    n_updates            | 2250          |\n",
      "|    policy_gradient_loss | -0.000249     |\n",
      "|    value_loss           | 0.732         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.06e+03     |\n",
      "|    ep_rew_mean          | -2.83        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 227          |\n",
      "|    time_elapsed         | 1008         |\n",
      "|    total_timesteps      | 464896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007420874 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0668      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.376        |\n",
      "|    n_updates            | 2260         |\n",
      "|    policy_gradient_loss | -0.000416    |\n",
      "|    value_loss           | 0.753        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.07e+03      |\n",
      "|    ep_rew_mean          | -2.91         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 461           |\n",
      "|    iterations           | 228           |\n",
      "|    time_elapsed         | 1012          |\n",
      "|    total_timesteps      | 466944        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00056391186 |\n",
      "|    clip_fraction        | 0.00649       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0489       |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.345         |\n",
      "|    n_updates            | 2270          |\n",
      "|    policy_gradient_loss | -0.000725     |\n",
      "|    value_loss           | 0.692         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.08e+03     |\n",
      "|    ep_rew_mean          | -2.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 229          |\n",
      "|    time_elapsed         | 1016         |\n",
      "|    total_timesteps      | 468992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005005441 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0461      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.343        |\n",
      "|    n_updates            | 2280         |\n",
      "|    policy_gradient_loss | -0.000179    |\n",
      "|    value_loss           | 0.686        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.08e+03     |\n",
      "|    ep_rew_mean          | -2.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 230          |\n",
      "|    time_elapsed         | 1020         |\n",
      "|    total_timesteps      | 471040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004300059 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0296      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.162        |\n",
      "|    n_updates            | 2290         |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    value_loss           | 0.327        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.11e+03      |\n",
      "|    ep_rew_mean          | -2.83         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 461           |\n",
      "|    iterations           | 231           |\n",
      "|    time_elapsed         | 1025          |\n",
      "|    total_timesteps      | 473088        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017390653 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0261       |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.000972      |\n",
      "|    n_updates            | 2300          |\n",
      "|    policy_gradient_loss | -0.000261     |\n",
      "|    value_loss           | 0.00317       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -2.96        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 232          |\n",
      "|    time_elapsed         | 1029         |\n",
      "|    total_timesteps      | 475136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071018264 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0619      |\n",
      "|    explained_variance   | 2.38e-07     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.00705      |\n",
      "|    n_updates            | 2310         |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    value_loss           | 0.0196       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | -3.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 1033         |\n",
      "|    total_timesteps      | 477184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029643462 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.096       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.652        |\n",
      "|    n_updates            | 2320         |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    value_loss           | 1.32         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | -3.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 234          |\n",
      "|    time_elapsed         | 1037         |\n",
      "|    total_timesteps      | 479232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013103248 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0682      |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.333        |\n",
      "|    n_updates            | 2330         |\n",
      "|    policy_gradient_loss | -0.000679    |\n",
      "|    value_loss           | 0.671        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.1e+03       |\n",
      "|    ep_rew_mean          | -2.95         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 461           |\n",
      "|    iterations           | 235           |\n",
      "|    time_elapsed         | 1041          |\n",
      "|    total_timesteps      | 481280        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021293643 |\n",
      "|    clip_fraction        | 0.00381       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0662       |\n",
      "|    explained_variance   | 1.79e-07      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.38          |\n",
      "|    n_updates            | 2340          |\n",
      "|    policy_gradient_loss | -0.000567     |\n",
      "|    value_loss           | 0.762         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | -2.97        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 1045         |\n",
      "|    total_timesteps      | 483328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007497714 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0637      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.518        |\n",
      "|    n_updates            | 2350         |\n",
      "|    policy_gradient_loss | -0.00043     |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.12e+03      |\n",
      "|    ep_rew_mean          | -2.8          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 462           |\n",
      "|    iterations           | 237           |\n",
      "|    time_elapsed         | 1050          |\n",
      "|    total_timesteps      | 485376        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013612062 |\n",
      "|    clip_fraction        | 0.00156       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0674       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.184         |\n",
      "|    n_updates            | 2360          |\n",
      "|    policy_gradient_loss | -0.00026      |\n",
      "|    value_loss           | 0.369         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.12e+03      |\n",
      "|    ep_rew_mean          | -2.8          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 462           |\n",
      "|    iterations           | 238           |\n",
      "|    time_elapsed         | 1054          |\n",
      "|    total_timesteps      | 487424        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042974908 |\n",
      "|    clip_fraction        | 0.00488       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0633       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.504         |\n",
      "|    n_updates            | 2370          |\n",
      "|    policy_gradient_loss | -0.000837     |\n",
      "|    value_loss           | 1.01          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | -2.88        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 239          |\n",
      "|    time_elapsed         | 1058         |\n",
      "|    total_timesteps      | 489472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031631829 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0487      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.33         |\n",
      "|    n_updates            | 2380         |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    value_loss           | 0.664        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -2.86       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 462         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 1062        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000849618 |\n",
      "|    clip_fraction        | 0.00332     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0371     |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 0.179       |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    value_loss           | 0.362       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -2.81        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 241          |\n",
      "|    time_elapsed         | 1066         |\n",
      "|    total_timesteps      | 493568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.328046e-06 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.052       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.179        |\n",
      "|    n_updates            | 2400         |\n",
      "|    policy_gradient_loss | 1.41e-05     |\n",
      "|    value_loss           | 0.358        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.13e+03     |\n",
      "|    ep_rew_mean          | -2.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 242          |\n",
      "|    time_elapsed         | 1070         |\n",
      "|    total_timesteps      | 495616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001977483 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0429      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.175        |\n",
      "|    n_updates            | 2410         |\n",
      "|    policy_gradient_loss | -0.000316    |\n",
      "|    value_loss           | 0.352        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -2.69        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 1075         |\n",
      "|    total_timesteps      | 497664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028116968 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.07        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.00526      |\n",
      "|    n_updates            | 2420         |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    value_loss           | 0.0155       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -2.85        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 244          |\n",
      "|    time_elapsed         | 1079         |\n",
      "|    total_timesteps      | 499712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023311255 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0942      |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.514        |\n",
      "|    n_updates            | 2430         |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 1.03         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -2.95        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 245          |\n",
      "|    time_elapsed         | 1083         |\n",
      "|    total_timesteps      | 501760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012333819 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.089       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.487        |\n",
      "|    n_updates            | 2440         |\n",
      "|    policy_gradient_loss | -0.000915    |\n",
      "|    value_loss           | 0.983        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.1e+03       |\n",
      "|    ep_rew_mean          | -3.01         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 463           |\n",
      "|    iterations           | 246           |\n",
      "|    time_elapsed         | 1088          |\n",
      "|    total_timesteps      | 503808        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052299845 |\n",
      "|    clip_fraction        | 0.00806       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0582       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.33          |\n",
      "|    n_updates            | 2450          |\n",
      "|    policy_gradient_loss | -0.000568     |\n",
      "|    value_loss           | 0.663         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.11e+03      |\n",
      "|    ep_rew_mean          | -2.97         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 463           |\n",
      "|    iterations           | 247           |\n",
      "|    time_elapsed         | 1092          |\n",
      "|    total_timesteps      | 505856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039131846 |\n",
      "|    clip_fraction        | 0.00371       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0625       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.354         |\n",
      "|    n_updates            | 2460          |\n",
      "|    policy_gradient_loss | -0.00108      |\n",
      "|    value_loss           | 0.711         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.1e+03       |\n",
      "|    ep_rew_mean          | -2.96         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 463           |\n",
      "|    iterations           | 248           |\n",
      "|    time_elapsed         | 1096          |\n",
      "|    total_timesteps      | 507904        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.4868008e-05 |\n",
      "|    clip_fraction        | 0.00215       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.061        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.377         |\n",
      "|    n_updates            | 2470          |\n",
      "|    policy_gradient_loss | -6.91e-05     |\n",
      "|    value_loss           | 0.754         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -2.89        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 463          |\n",
      "|    iterations           | 249          |\n",
      "|    time_elapsed         | 1100         |\n",
      "|    total_timesteps      | 509952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002018782 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0485      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.346        |\n",
      "|    n_updates            | 2480         |\n",
      "|    policy_gradient_loss | -0.000277    |\n",
      "|    value_loss           | 0.694        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.1e+03       |\n",
      "|    ep_rew_mean          | -2.81         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 463           |\n",
      "|    iterations           | 250           |\n",
      "|    time_elapsed         | 1104          |\n",
      "|    total_timesteps      | 512000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6943162e-05 |\n",
      "|    clip_fraction        | 0.00439       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0593       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.209         |\n",
      "|    n_updates            | 2490          |\n",
      "|    policy_gradient_loss | -0.000618     |\n",
      "|    value_loss           | 0.419         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.11e+03      |\n",
      "|    ep_rew_mean          | -2.8          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 463           |\n",
      "|    iterations           | 251           |\n",
      "|    time_elapsed         | 1108          |\n",
      "|    total_timesteps      | 514048        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025642128 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0537       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.354         |\n",
      "|    n_updates            | 2500          |\n",
      "|    policy_gradient_loss | -0.000118     |\n",
      "|    value_loss           | 0.709         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -2.87        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 463          |\n",
      "|    iterations           | 252          |\n",
      "|    time_elapsed         | 1113         |\n",
      "|    total_timesteps      | 516096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.831724e-05 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.049       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.203        |\n",
      "|    n_updates            | 2510         |\n",
      "|    policy_gradient_loss | -0.000323    |\n",
      "|    value_loss           | 0.406        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -2.87        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 463          |\n",
      "|    iterations           | 253          |\n",
      "|    time_elapsed         | 1117         |\n",
      "|    total_timesteps      | 518144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013424231 |\n",
      "|    clip_fraction        | 0.00444      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0334      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.335        |\n",
      "|    n_updates            | 2520         |\n",
      "|    policy_gradient_loss | -0.000748    |\n",
      "|    value_loss           | 0.671        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+03     |\n",
      "|    ep_rew_mean          | -2.75        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 463          |\n",
      "|    iterations           | 254          |\n",
      "|    time_elapsed         | 1121         |\n",
      "|    total_timesteps      | 520192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022635178 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0408      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.0104       |\n",
      "|    n_updates            | 2530         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 0.0295       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.15e+03      |\n",
      "|    ep_rew_mean          | -2.58         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 464           |\n",
      "|    iterations           | 255           |\n",
      "|    time_elapsed         | 1125          |\n",
      "|    total_timesteps      | 522240        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033878628 |\n",
      "|    clip_fraction        | 0.00234       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0565       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.341         |\n",
      "|    n_updates            | 2540          |\n",
      "|    policy_gradient_loss | -0.000192     |\n",
      "|    value_loss           | 0.682         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | -2.48       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 464         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 1129        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007271223 |\n",
      "|    clip_fraction        | 0.00586     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0817     |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 0.0195      |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    value_loss           | 0.0567      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.05e+03     |\n",
      "|    ep_rew_mean          | -2.45        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 464          |\n",
      "|    iterations           | 257          |\n",
      "|    time_elapsed         | 1133         |\n",
      "|    total_timesteps      | 526336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013588935 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.125       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 2560         |\n",
      "|    policy_gradient_loss | -0.000306    |\n",
      "|    value_loss           | 2.41         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.03e+03      |\n",
      "|    ep_rew_mean          | -2.34         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 464           |\n",
      "|    iterations           | 258           |\n",
      "|    time_elapsed         | 1138          |\n",
      "|    total_timesteps      | 528384        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010969481 |\n",
      "|    clip_fraction        | 0.00171       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.11         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.561         |\n",
      "|    n_updates            | 2570          |\n",
      "|    policy_gradient_loss | -0.00015      |\n",
      "|    value_loss           | 1.12          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | -2.26         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 464           |\n",
      "|    iterations           | 259           |\n",
      "|    time_elapsed         | 1142          |\n",
      "|    total_timesteps      | 530432        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8781808e-05 |\n",
      "|    clip_fraction        | 0.00488       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.102        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.918         |\n",
      "|    n_updates            | 2580          |\n",
      "|    policy_gradient_loss | -0.000281     |\n",
      "|    value_loss           | 1.84          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 991           |\n",
      "|    ep_rew_mean          | -2.26         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 464           |\n",
      "|    iterations           | 260           |\n",
      "|    time_elapsed         | 1146          |\n",
      "|    total_timesteps      | 532480        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064244226 |\n",
      "|    clip_fraction        | 0.00645       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0962       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.862         |\n",
      "|    n_updates            | 2590          |\n",
      "|    policy_gradient_loss | -0.000738     |\n",
      "|    value_loss           | 1.73          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 954           |\n",
      "|    ep_rew_mean          | -2.32         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 464           |\n",
      "|    iterations           | 261           |\n",
      "|    time_elapsed         | 1150          |\n",
      "|    total_timesteps      | 534528        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.2479656e-05 |\n",
      "|    clip_fraction        | 0.00244       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.102        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.389         |\n",
      "|    n_updates            | 2600          |\n",
      "|    policy_gradient_loss | -0.000194     |\n",
      "|    value_loss           | 0.779         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 926          |\n",
      "|    ep_rew_mean          | -2.25        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 464          |\n",
      "|    iterations           | 262          |\n",
      "|    time_elapsed         | 1154         |\n",
      "|    total_timesteps      | 536576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.180306e-05 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0862      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.892        |\n",
      "|    n_updates            | 2610         |\n",
      "|    policy_gradient_loss | -0.000621    |\n",
      "|    value_loss           | 1.79         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 907           |\n",
      "|    ep_rew_mean          | -2.16         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 464           |\n",
      "|    iterations           | 263           |\n",
      "|    time_elapsed         | 1159          |\n",
      "|    total_timesteps      | 538624        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070314854 |\n",
      "|    clip_fraction        | 0.00376       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.108        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.723         |\n",
      "|    n_updates            | 2620          |\n",
      "|    policy_gradient_loss | 0.000115      |\n",
      "|    value_loss           | 1.45          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 887           |\n",
      "|    ep_rew_mean          | -2.26         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 464           |\n",
      "|    iterations           | 264           |\n",
      "|    time_elapsed         | 1163          |\n",
      "|    total_timesteps      | 540672        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3811568e-05 |\n",
      "|    clip_fraction        | 0.00396       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0762       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.541         |\n",
      "|    n_updates            | 2630          |\n",
      "|    policy_gradient_loss | -0.000226     |\n",
      "|    value_loss           | 1.08          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 885          |\n",
      "|    ep_rew_mean          | -2.27        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 464          |\n",
      "|    iterations           | 265          |\n",
      "|    time_elapsed         | 1167         |\n",
      "|    total_timesteps      | 542720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007288214 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0703      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.477        |\n",
      "|    n_updates            | 2640         |\n",
      "|    policy_gradient_loss | -0.000704    |\n",
      "|    value_loss           | 0.955        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 894           |\n",
      "|    ep_rew_mean          | -2.31         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 464           |\n",
      "|    iterations           | 266           |\n",
      "|    time_elapsed         | 1171          |\n",
      "|    total_timesteps      | 544768        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7619844e-05 |\n",
      "|    clip_fraction        | 0.00215       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0711       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.372         |\n",
      "|    n_updates            | 2650          |\n",
      "|    policy_gradient_loss | -4.27e-05     |\n",
      "|    value_loss           | 0.744         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 891           |\n",
      "|    ep_rew_mean          | -2.35         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 464           |\n",
      "|    iterations           | 267           |\n",
      "|    time_elapsed         | 1176          |\n",
      "|    total_timesteps      | 546816        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029201643 |\n",
      "|    clip_fraction        | 0.00439       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0562       |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.352         |\n",
      "|    n_updates            | 2660          |\n",
      "|    policy_gradient_loss | -0.000778     |\n",
      "|    value_loss           | 0.706         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 886           |\n",
      "|    ep_rew_mean          | -2.42         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 464           |\n",
      "|    iterations           | 268           |\n",
      "|    time_elapsed         | 1180          |\n",
      "|    total_timesteps      | 548864        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035215425 |\n",
      "|    clip_fraction        | 0.00659       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0548       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.519         |\n",
      "|    n_updates            | 2670          |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    value_loss           | 1.04          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 888          |\n",
      "|    ep_rew_mean          | -2.58        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 269          |\n",
      "|    time_elapsed         | 1184         |\n",
      "|    total_timesteps      | 550912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012533042 |\n",
      "|    clip_fraction        | 0.00747      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0557      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.339        |\n",
      "|    n_updates            | 2680         |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    value_loss           | 0.681        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 893          |\n",
      "|    ep_rew_mean          | -2.51        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 270          |\n",
      "|    time_elapsed         | 1188         |\n",
      "|    total_timesteps      | 552960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013562675 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0507      |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.49         |\n",
      "|    n_updates            | 2690         |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    value_loss           | 0.986        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 825          |\n",
      "|    ep_rew_mean          | -2.67        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 271          |\n",
      "|    time_elapsed         | 1193         |\n",
      "|    total_timesteps      | 555008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032321576 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0645      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.00608      |\n",
      "|    n_updates            | 2700         |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    value_loss           | 0.0162       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 828          |\n",
      "|    ep_rew_mean          | -2.67        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 272          |\n",
      "|    time_elapsed         | 1197         |\n",
      "|    total_timesteps      | 557056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015991156 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0631      |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.791        |\n",
      "|    n_updates            | 2710         |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    value_loss           | 1.59         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 834          |\n",
      "|    ep_rew_mean          | -2.69        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 273          |\n",
      "|    time_elapsed         | 1201         |\n",
      "|    total_timesteps      | 559104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017418064 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0403      |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.459        |\n",
      "|    n_updates            | 2720         |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    value_loss           | 0.922        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 834          |\n",
      "|    ep_rew_mean          | -2.69        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 274          |\n",
      "|    time_elapsed         | 1205         |\n",
      "|    total_timesteps      | 561152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003186154 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0325      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.154        |\n",
      "|    n_updates            | 2730         |\n",
      "|    policy_gradient_loss | -0.000811    |\n",
      "|    value_loss           | 0.31         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 856           |\n",
      "|    ep_rew_mean          | -2.69         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 465           |\n",
      "|    iterations           | 275           |\n",
      "|    time_elapsed         | 1209          |\n",
      "|    total_timesteps      | 563200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040201395 |\n",
      "|    clip_fraction        | 0.00176       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0368       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.00264       |\n",
      "|    n_updates            | 2740          |\n",
      "|    policy_gradient_loss | -0.000464     |\n",
      "|    value_loss           | 0.00647       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 866           |\n",
      "|    ep_rew_mean          | -2.77         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 465           |\n",
      "|    iterations           | 276           |\n",
      "|    time_elapsed         | 1213          |\n",
      "|    total_timesteps      | 565248        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091086247 |\n",
      "|    clip_fraction        | 0.00381       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0381       |\n",
      "|    explained_variance   | 0.0428        |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.158         |\n",
      "|    n_updates            | 2750          |\n",
      "|    policy_gradient_loss | -0.000985     |\n",
      "|    value_loss           | 0.309         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 866           |\n",
      "|    ep_rew_mean          | -2.77         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 465           |\n",
      "|    iterations           | 277           |\n",
      "|    time_elapsed         | 1217          |\n",
      "|    total_timesteps      | 567296        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068111665 |\n",
      "|    clip_fraction        | 0.00234       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0236       |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.32          |\n",
      "|    n_updates            | 2760          |\n",
      "|    policy_gradient_loss | -0.00061      |\n",
      "|    value_loss           | 0.641         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 900          |\n",
      "|    ep_rew_mean          | -2.79        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 278          |\n",
      "|    time_elapsed         | 1221         |\n",
      "|    total_timesteps      | 569344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016164834 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0298      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.00597      |\n",
      "|    n_updates            | 2770         |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    value_loss           | 0.0187       |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 905            |\n",
      "|    ep_rew_mean          | -2.67          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 466            |\n",
      "|    iterations           | 279            |\n",
      "|    time_elapsed         | 1226           |\n",
      "|    total_timesteps      | 571392         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000102856284 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.0509        |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.0025         |\n",
      "|    loss                 | 0.342          |\n",
      "|    n_updates            | 2780           |\n",
      "|    policy_gradient_loss | 4.36e-05       |\n",
      "|    value_loss           | 0.686          |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 867         |\n",
      "|    ep_rew_mean          | -2.63       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 466         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 1230        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007263768 |\n",
      "|    clip_fraction        | 0.00513     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0687     |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0025      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    value_loss           | 0.0741      |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 810           |\n",
      "|    ep_rew_mean          | -2.65         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 466           |\n",
      "|    iterations           | 281           |\n",
      "|    time_elapsed         | 1234          |\n",
      "|    total_timesteps      | 575488        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032366446 |\n",
      "|    clip_fraction        | 0.00518       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.129        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 1.12          |\n",
      "|    n_updates            | 2800          |\n",
      "|    policy_gradient_loss | -0.000283     |\n",
      "|    value_loss           | 2.24          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 794          |\n",
      "|    ep_rew_mean          | -2.47        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 282          |\n",
      "|    time_elapsed         | 1238         |\n",
      "|    total_timesteps      | 577536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.554255e-05 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.104       |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.919        |\n",
      "|    n_updates            | 2810         |\n",
      "|    policy_gradient_loss | -9.57e-05    |\n",
      "|    value_loss           | 1.84         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 792          |\n",
      "|    ep_rew_mean          | -2.28        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 283          |\n",
      "|    time_elapsed         | 1243         |\n",
      "|    total_timesteps      | 579584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004553935 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.117       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.689        |\n",
      "|    n_updates            | 2820         |\n",
      "|    policy_gradient_loss | -0.000158    |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 762          |\n",
      "|    ep_rew_mean          | -2.34        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 284          |\n",
      "|    time_elapsed         | 1247         |\n",
      "|    total_timesteps      | 581632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009141714 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.1         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.73         |\n",
      "|    n_updates            | 2830         |\n",
      "|    policy_gradient_loss | -0.000525    |\n",
      "|    value_loss           | 1.46         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 743          |\n",
      "|    ep_rew_mean          | -2.33        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 285          |\n",
      "|    time_elapsed         | 1251         |\n",
      "|    total_timesteps      | 583680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013480581 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0945      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.739        |\n",
      "|    n_updates            | 2840         |\n",
      "|    policy_gradient_loss | -0.000407    |\n",
      "|    value_loss           | 1.48         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 728          |\n",
      "|    ep_rew_mean          | -2.41        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 286          |\n",
      "|    time_elapsed         | 1255         |\n",
      "|    total_timesteps      | 585728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.294408e-05 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0874      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.599        |\n",
      "|    n_updates            | 2850         |\n",
      "|    policy_gradient_loss | -0.000229    |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 694          |\n",
      "|    ep_rew_mean          | -2.35        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 287          |\n",
      "|    time_elapsed         | 1259         |\n",
      "|    total_timesteps      | 587776       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004318658 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0671      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.519        |\n",
      "|    n_updates            | 2860         |\n",
      "|    policy_gradient_loss | -0.000356    |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 688           |\n",
      "|    ep_rew_mean          | -2.48         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 466           |\n",
      "|    iterations           | 288           |\n",
      "|    time_elapsed         | 1264          |\n",
      "|    total_timesteps      | 589824        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00055412354 |\n",
      "|    clip_fraction        | 0.00425       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0705       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.537         |\n",
      "|    n_updates            | 2870          |\n",
      "|    policy_gradient_loss | -0.000244     |\n",
      "|    value_loss           | 1.07          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 692           |\n",
      "|    ep_rew_mean          | -2.49         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 466           |\n",
      "|    iterations           | 289           |\n",
      "|    time_elapsed         | 1268          |\n",
      "|    total_timesteps      | 591872        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012446477 |\n",
      "|    clip_fraction        | 0.00425       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0471       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.362         |\n",
      "|    n_updates            | 2880          |\n",
      "|    policy_gradient_loss | -8.62e-05     |\n",
      "|    value_loss           | 0.725         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 704          |\n",
      "|    ep_rew_mean          | -2.48        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 290          |\n",
      "|    time_elapsed         | 1272         |\n",
      "|    total_timesteps      | 593920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.151711e-05 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0564      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.184        |\n",
      "|    n_updates            | 2890         |\n",
      "|    policy_gradient_loss | -0.000134    |\n",
      "|    value_loss           | 0.369        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 719           |\n",
      "|    ep_rew_mean          | -2.42         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 466           |\n",
      "|    iterations           | 291           |\n",
      "|    time_elapsed         | 1276          |\n",
      "|    total_timesteps      | 595968        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.1823695e-05 |\n",
      "|    clip_fraction        | 0.00361       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0612       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.203         |\n",
      "|    n_updates            | 2900          |\n",
      "|    policy_gradient_loss | -0.000573     |\n",
      "|    value_loss           | 0.408         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 729           |\n",
      "|    ep_rew_mean          | -2.42         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 466           |\n",
      "|    iterations           | 292           |\n",
      "|    time_elapsed         | 1280          |\n",
      "|    total_timesteps      | 598016        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026196428 |\n",
      "|    clip_fraction        | 0.00156       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.054        |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.343         |\n",
      "|    n_updates            | 2910          |\n",
      "|    policy_gradient_loss | -0.000101     |\n",
      "|    value_loss           | 0.686         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 743           |\n",
      "|    ep_rew_mean          | -2.51         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 466           |\n",
      "|    iterations           | 293           |\n",
      "|    time_elapsed         | 1285          |\n",
      "|    total_timesteps      | 600064        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034503185 |\n",
      "|    clip_fraction        | 0.00151       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.047        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.175         |\n",
      "|    n_updates            | 2920          |\n",
      "|    policy_gradient_loss | -0.000322     |\n",
      "|    value_loss           | 0.351         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 771           |\n",
      "|    ep_rew_mean          | -2.46         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 466           |\n",
      "|    iterations           | 294           |\n",
      "|    time_elapsed         | 1289          |\n",
      "|    total_timesteps      | 602112        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020591065 |\n",
      "|    clip_fraction        | 0.00156       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0381       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.183         |\n",
      "|    n_updates            | 2930          |\n",
      "|    policy_gradient_loss | -0.000218     |\n",
      "|    value_loss           | 0.367         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 779          |\n",
      "|    ep_rew_mean          | -2.54        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 295          |\n",
      "|    time_elapsed         | 1293         |\n",
      "|    total_timesteps      | 604160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004462927 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0334      |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.346        |\n",
      "|    n_updates            | 2940         |\n",
      "|    policy_gradient_loss | -0.000433    |\n",
      "|    value_loss           | 0.693        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 801          |\n",
      "|    ep_rew_mean          | -2.58        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 296          |\n",
      "|    time_elapsed         | 1297         |\n",
      "|    total_timesteps      | 606208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003608207 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0246      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.167        |\n",
      "|    n_updates            | 2950         |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    value_loss           | 0.336        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 801           |\n",
      "|    ep_rew_mean          | -2.58         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 467           |\n",
      "|    iterations           | 297           |\n",
      "|    time_elapsed         | 1301          |\n",
      "|    total_timesteps      | 608256        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029760023 |\n",
      "|    clip_fraction        | 0.0022        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0203       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.17          |\n",
      "|    n_updates            | 2960          |\n",
      "|    policy_gradient_loss | -0.000382     |\n",
      "|    value_loss           | 0.342         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 826          |\n",
      "|    ep_rew_mean          | -2.58        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 298          |\n",
      "|    time_elapsed         | 1306         |\n",
      "|    total_timesteps      | 610304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013676778 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0274      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.00653      |\n",
      "|    n_updates            | 2970         |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    value_loss           | 0.0191       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 834           |\n",
      "|    ep_rew_mean          | -2.55         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 467           |\n",
      "|    iterations           | 299           |\n",
      "|    time_elapsed         | 1310          |\n",
      "|    total_timesteps      | 612352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019039327 |\n",
      "|    clip_fraction        | 0.00366       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0477       |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.212         |\n",
      "|    n_updates            | 2980          |\n",
      "|    policy_gradient_loss | -0.000763     |\n",
      "|    value_loss           | 0.426         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 862          |\n",
      "|    ep_rew_mean          | -2.62        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 300          |\n",
      "|    time_elapsed         | 1314         |\n",
      "|    total_timesteps      | 614400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004604704 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0413      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.169        |\n",
      "|    n_updates            | 2990         |\n",
      "|    policy_gradient_loss | -0.000763    |\n",
      "|    value_loss           | 0.341        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 881          |\n",
      "|    ep_rew_mean          | -2.64        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 301          |\n",
      "|    time_elapsed         | 1318         |\n",
      "|    total_timesteps      | 616448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.415904e-05 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0325      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.328        |\n",
      "|    n_updates            | 3000         |\n",
      "|    policy_gradient_loss | -0.000488    |\n",
      "|    value_loss           | 0.658        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 898          |\n",
      "|    ep_rew_mean          | -2.64        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 302          |\n",
      "|    time_elapsed         | 1323         |\n",
      "|    total_timesteps      | 618496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011641143 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0497      |\n",
      "|    explained_variance   | -0.238       |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.0754       |\n",
      "|    n_updates            | 3010         |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    value_loss           | 0.273        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 906          |\n",
      "|    ep_rew_mean          | -2.63        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 303          |\n",
      "|    time_elapsed         | 1327         |\n",
      "|    total_timesteps      | 620544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.156007e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0439      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.189        |\n",
      "|    n_updates            | 3020         |\n",
      "|    policy_gradient_loss | -7.88e-06    |\n",
      "|    value_loss           | 0.378        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 920          |\n",
      "|    ep_rew_mean          | -2.63        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 304          |\n",
      "|    time_elapsed         | 1331         |\n",
      "|    total_timesteps      | 622592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.119812e-05 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0503      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.394        |\n",
      "|    n_updates            | 3030         |\n",
      "|    policy_gradient_loss | -0.000251    |\n",
      "|    value_loss           | 0.789        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 929           |\n",
      "|    ep_rew_mean          | -2.61         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 467           |\n",
      "|    iterations           | 305           |\n",
      "|    time_elapsed         | 1335          |\n",
      "|    total_timesteps      | 624640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3783144e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0523       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0025        |\n",
      "|    loss                 | 0.377         |\n",
      "|    n_updates            | 3040          |\n",
      "|    policy_gradient_loss | 1.17e-05      |\n",
      "|    value_loss           | 0.754         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 936          |\n",
      "|    ep_rew_mean          | -2.65        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 306          |\n",
      "|    time_elapsed         | 1339         |\n",
      "|    total_timesteps      | 626688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003508608 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0434      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.343        |\n",
      "|    n_updates            | 3050         |\n",
      "|    policy_gradient_loss | -0.000185    |\n",
      "|    value_loss           | 0.687        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 946          |\n",
      "|    ep_rew_mean          | -2.73        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 307          |\n",
      "|    time_elapsed         | 1344         |\n",
      "|    total_timesteps      | 628736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001641988 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0461      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.181        |\n",
      "|    n_updates            | 3060         |\n",
      "|    policy_gradient_loss | -0.000217    |\n",
      "|    value_loss           | 0.364        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 968          |\n",
      "|    ep_rew_mean          | -2.61        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 308          |\n",
      "|    time_elapsed         | 1348         |\n",
      "|    total_timesteps      | 630784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010853714 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0288      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.173        |\n",
      "|    n_updates            | 3070         |\n",
      "|    policy_gradient_loss | -0.000677    |\n",
      "|    value_loss           | 0.347        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 962          |\n",
      "|    ep_rew_mean          | -2.99        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 309          |\n",
      "|    time_elapsed         | 1352         |\n",
      "|    total_timesteps      | 632832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042869914 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0445      |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.00356      |\n",
      "|    n_updates            | 3080         |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    value_loss           | 0.0132       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 965          |\n",
      "|    ep_rew_mean          | -3.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 310          |\n",
      "|    time_elapsed         | 1356         |\n",
      "|    total_timesteps      | 634880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025100787 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0633      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.994        |\n",
      "|    n_updates            | 3090         |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    value_loss           | 2.01         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 976          |\n",
      "|    ep_rew_mean          | -3.11        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 311          |\n",
      "|    time_elapsed         | 1361         |\n",
      "|    total_timesteps      | 636928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.629468e-06 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0659      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0025       |\n",
      "|    loss                 | 0.186        |\n",
      "|    n_updates            | 3100         |\n",
      "|    policy_gradient_loss | 7.13e-05     |\n",
      "|    value_loss           | 0.372        |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import os for file path management\n",
    "import os\n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "# Import Summary Writer for logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# Import t2xy for plotting\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, tensorboard_log, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        self.tensorboard_log = tensorboard_log\n",
    "        self.writer = SummaryWriter(tensorboard_log)\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "            # Log the mean reward to TensorBoard use t2xy\n",
    "            x, y = ts2xy(load_results(self.tensorboard_log), 'timesteps')\n",
    "            if len(x) > 0:\n",
    "                self.writer.add_scalar('reward', y[-1], x[-1])\n",
    "        return True            \n",
    "    \n",
    "\n",
    "CHECKPOINT_DIR = './train_modeldata/'\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)\n",
    "\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR, tensorboard_log=LOG_DIR)\n",
    "\n",
    "env = TradingEnv(data) \n",
    "env = Monitor(env, LOG_DIR)\n",
    "\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, n_stack=frame_skip_frequency)\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameters\n",
    "model_params = {\n",
    "    'n_steps': 2048,\n",
    "    'ent_coef': 0.0,\n",
    "    'learning_rate': 0.0025,\n",
    "    'gamma': 0.99,\n",
    "    'gae_lambda': 0.95,\n",
    "    'clip_range': 0.2,\n",
    "    'vf_coef': 0.5,\n",
    "    'max_grad_norm': 0.5,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model = PPO('MlpPolicy',env,tensorboard_log= LOG_DIR , batch_size=4096, verbose=1, **model_params)\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps, callback=callback)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
